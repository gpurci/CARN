{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x55A6JvfHaAK"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG8McvlDHd8u",
        "outputId": "df4bea62-04ab-44e4-8a61-025576b835d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting livelossplot\n",
            "  Downloading livelossplot-0.5.6-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from livelossplot) (3.10.0)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.12/dist-packages (from livelossplot) (3.7.3)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (3.1.6)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (1.3.3)\n",
            "Requirement already satisfied: narwhals>=1.13 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (2.0.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (25.0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (2.2.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (11.3.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (6.0.3)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (6.4.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (2025.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->livelossplot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->livelossplot) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->livelossplot) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->livelossplot) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->livelossplot) (2.9.0.post0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (3.0.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.17.0)\n",
            "Downloading livelossplot-0.5.6-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: livelossplot\n",
            "Successfully installed livelossplot-0.5.6\n"
          ]
        }
      ],
      "source": [
        "!pip install livelossplot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xQA0TbS9iJz"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JnlB_3F-4Ypz"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torch\n",
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import traceback\n",
        "from pathlib import Path\n",
        "from livelossplot import PlotLossesKeras\n",
        "\n",
        "# You are not allowed to use DataLoader, torch.nn, torch.functional, torchvision\n",
        "# Backpropagation and data preprocessing must be implemented from scratch\n",
        "# Check https://github.com/Tensor-Reloaded/AI-Learning-Hub/blob/main/how_to/use_kaggle.md for learning how to use kaggle and submit to this competition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MavX5UXd_jqX"
      },
      "source": [
        "# Data aquisition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gsQ54N4Hy2Y"
      },
      "source": [
        "## Preprocesing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a3sb7JXDHzWh"
      },
      "outputs": [],
      "source": [
        "\n",
        "def normalization_n1_p1(x):\n",
        "    return (x/127.5)-1\n",
        "\n",
        "def normalization_n0_p1(x):\n",
        "    return x/255\n",
        "\n",
        "def one_hot(y, num_classes=1):\n",
        "    #print(y.shape, y)\n",
        "    tmp = torch.zeros((y.size(0), num_classes), dtype=torch.float32)\n",
        "    tmp[torch.arange(y.size(0)), y] = 1.0\n",
        "    return tmp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp35IrNCH1ED"
      },
      "source": [
        "## Summary function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O8ajvvlBH6TJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def test_dataset_fn(img, label):\n",
        "    info_str = \"\"\"img: shape {}, min {}, max {}, type {};\n",
        "label: shape {}, min {}, max {}, type {};\"\"\".format(img.shape, torch.min(img), torch.max(img), type(img),\n",
        "                                           label.shape, torch.min(label), torch.max(label), type(label))\n",
        "    print(info_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6JV4BsOHsBz"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JPQpvpRF_mM3"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ExtendedMNISTDataset(Dataset):\n",
        "    def __init__(self, root: str = \"/kaggle/input/fii-atnn-2025-competition-1\", train: bool = True):\n",
        "        \"\"\"ExtendedMNISTDataset:\n",
        "        root  - path root of dataset\n",
        "        train - read train or test dataset (true - train, false - test)\n",
        "        preprocessing - image preprocesing function\n",
        "        Dataset structure:\n",
        "            list -> (batchsize, tuple -> (np.array -> (image->(784, )), scalar -> (labels->1)))\n",
        "        \"\"\"\n",
        "        # select filename\n",
        "        if (train):\n",
        "            file = \"extended_mnist_train.pkl\"\n",
        "        else:\n",
        "            file = \"extended_mnist_test.pkl\"\n",
        "        # join root to filename\n",
        "        filename = os.path.join(root, file)\n",
        "        # read dataset\n",
        "        dataset = self.__read(filename)\n",
        "        self.inputs, self.outputs = self.__split_data(dataset)\n",
        "\n",
        "    def __read(self, filename):\n",
        "        # try to open filename\n",
        "        try:\n",
        "            f = open(filename, \"rb\")\n",
        "            try:\n",
        "                dataset = pickle.load(f)\n",
        "            except Exception as e:\n",
        "                dataset = None\n",
        "                self.__show_exception(e)\n",
        "            finally:\n",
        "                f.close()\n",
        "        except IOError as e:\n",
        "            dataset = None\n",
        "            self.__show_exception(e)\n",
        "        return dataset\n",
        "\n",
        "    def __show_exception(self, e) -> None:\n",
        "        tb = traceback.extract_tb(e.__traceback__)\n",
        "        last_call = tb[-1]\n",
        "        print(f\"❌ Error in function '{last_call.name}' at line {last_call.lineno}\")\n",
        "        print(f\"   File: {last_call.filename}\")\n",
        "        print(f\"   Exception: {e}\")\n",
        "\n",
        "    def __split_data(self, dataset):\n",
        "        inputs  = []\n",
        "        outputs = []\n",
        "        for input, ouput in dataset:\n",
        "            inputs.append(input)\n",
        "            outputs.append(ouput)\n",
        "        return np.array(inputs, dtype=np.uint8), np.array(outputs, dtype=np.int32)\n",
        "\n",
        "    def __len__(self, ) -> int:\n",
        "        return self.inputs.shape[0]\n",
        "\n",
        "    def __getitem__(self, i : int):# int|np array\n",
        "        return self.inputs[i], self.outputs[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "s0FzmsLLAw8Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "c16fbd1a-71b6-4863-e781-b5fce287a74f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Error in function '__read' at line 24\n",
            "   File: /tmp/ipython-input-965428312.py\n",
            "   Exception: [Errno 2] No such file or directory: '/content/extended_mnist_train.pkl'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not iterable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4019775837.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtendedMNISTDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-965428312.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# read dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__split_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-965428312.py\u001b[0m in \u001b[0;36m__split_data\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0minputs\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
          ]
        }
      ],
      "source": [
        "#\n",
        "train_ds = ExtendedMNISTDataset(root=\"/content\", train=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqLrmx1JpUVq"
      },
      "outputs": [],
      "source": [
        "train_ds[[0, 1, 2]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHe3TjK9nCSB"
      },
      "outputs": [],
      "source": [
        "len(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HC5GijsbnFdW"
      },
      "outputs": [],
      "source": [
        "_, y = train_ds[np.arange(len(train_ds))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl_Zz0uhndHc"
      },
      "outputs": [],
      "source": [
        "y.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9nd7JEAH2aC"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TkXn5Zz1AwF6"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DataLoader(object):\n",
        "    def __init__(self, dataset, batchsize=1, shuffle=False):\n",
        "        assert (batchsize > 0), \"batchsize should be ghreat than 'zero'\"\n",
        "        assert (isinstance(shuffle, bool)), \"shuffle should be 'bool'\"\n",
        "        self.dataset = dataset\n",
        "        self.batchsize = batchsize\n",
        "        self.shuffle = shuffle\n",
        "        self.size = len(self.dataset)\n",
        "        # shufle\n",
        "        if (self.shuffle):\n",
        "            self.permutation = np.random.permutation(self.size)\n",
        "        else:\n",
        "            self.permutation = np.arange(self.size, dtype=np.int32)\n",
        "        self.maps_fn = []\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.dataset)//self.batchsize\n",
        "\n",
        "    def __call__(self):\n",
        "        try:\n",
        "            for i in range(0, self.size, self.batchsize):\n",
        "                pos  = self.permutation[i:i+self.batchsize]\n",
        "                datas = self.dataset[pos]\n",
        "                if (isinstance(datas, tuple)):\n",
        "                    datas = [torch.from_numpy(data) for data in datas]\n",
        "                else:\n",
        "                    datas = torch.from_numpy(datas)\n",
        "                datas = self.__map_fn(datas)\n",
        "                yield datas\n",
        "            else:\n",
        "                if (self.shuffle):\n",
        "                    self.permutation = np.random.permutation(self.size)\n",
        "        except Exception as e:\n",
        "            self.__show_exception(e)\n",
        "\n",
        "    def take(self, size):\n",
        "        try:\n",
        "            for i, data in zip(range(size), self()):\n",
        "                yield data\n",
        "            else:\n",
        "                pass\n",
        "        except Exception as e:\n",
        "            self.__show_exception(e)\n",
        "\n",
        "    def __show_exception(self, e) -> None:\n",
        "        tb = traceback.extract_tb(e.__traceback__)\n",
        "        last_call = tb[-1]\n",
        "        print(f\"❌ Error in function '{last_call.name}' at line {last_call.lineno}\")\n",
        "        print(f\"   File: {last_call.filename}\")\n",
        "        print(f\"   Exception: {e}\")\n",
        "\n",
        "    def map(self, fn):\n",
        "        self.maps_fn.append(fn)\n",
        "\n",
        "    def __map_fn(self, data):\n",
        "        for fn in self.maps_fn:\n",
        "            data = fn(*data)\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d144IRutFDMJ"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(train_ds, batchsize=20, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40WpDif0GcuQ"
      },
      "outputs": [],
      "source": [
        "dataloader.map(lambda x, y: (normalization_n1_p1(x), one_hot(y, num_classes=10)))\n",
        "dataloader.map(lambda x, y: (x.unsqueeze(-1), y.unsqueeze(-1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7uZwjchzB8SQ",
        "outputId": "9f1f77cc-c75d-4a58-c1a6-bb9cfb7030e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784, 1]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10, 1]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n"
          ]
        }
      ],
      "source": [
        "for img, label in dataloader.take(100):\n",
        "    test_dataset_fn(img, label)\n",
        "    #print(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8aGDKmc9tzF"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jCJPk8PR4YmX"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "A module to implement the stochastic gradient descent learning\n",
        "algorithm for a feedforward neural network.  Gradients are calculated\n",
        "using backpropagation.\n",
        "\"\"\"\n",
        "\n",
        "class SGD(object):\n",
        "\n",
        "    def __init__(self, parameters, lr):\n",
        "        \"\"\"\n",
        "        parameters - a list of parameters for every layer\n",
        "                    -> list of parameters\n",
        "                        -> one element of parameter is list of torch tensor\n",
        "        lr - learning rate\n",
        "        \"\"\"\n",
        "        self.__parameters = parameters\n",
        "        self.__lr = lr\n",
        "\n",
        "    def __call__(self, grads, batch_size):\n",
        "        \"\"\"\n",
        "        grads - a list of grads for every layer\n",
        "                    -> list of grads for parameters\n",
        "                        -> one element of grads is list of torch tensor\n",
        "        \"\"\"\n",
        "        #print(\"____optimizer____\")\n",
        "        eta = self.__lr/batch_size\n",
        "        #print(\"list layers: parameter {}, size {}, grad {}, size {}\".format(type(self.__parameters), len(self.__parameters), type(grads), len(grads)))\n",
        "        for l_parameters, l_grads in zip(self.__parameters, grads):\n",
        "            #print(\"list: parameters {}, grads {}\".format(type(l_parameters), type(l_grads)))\n",
        "            if ((l_grads is not None)):\n",
        "                for parameter, grad in zip(l_parameters, l_grads):\n",
        "                    #print(\"parameter {}, grad {}\".format(parameter.shape, grad.shape))\n",
        "                    torch.sub(parameter, grad, alpha=eta, out=parameter)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVslqY8VHz_V"
      },
      "source": [
        "# Build Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW3g5UadSVzk"
      },
      "source": [
        "## Build MetricsList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Z4RkFcnpH2RN"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MetricsList(object):\n",
        "    def __init__(self, metrics_fn):\n",
        "        \"\"\"\"\"\"\n",
        "        if (metrics_fn is not None):\n",
        "            if (isinstance(metrics_fn, (dict))):\n",
        "                for key in metrics_fn.keys():\n",
        "                    if (not isinstance(metrics_fn[key], Metrics)):\n",
        "                        raise NameError(\"The metric: '{}' is type '{}' not as 'Metrics' object\".format(key, type(metrics_fn[key])))\n",
        "            else:\n",
        "                raise NameError(\"The argument need to be as 'Dict' object, but is '{}'\".format(type(metrics_fn)))\n",
        "        else:\n",
        "            pass\n",
        "        #\n",
        "        self.__metrics_fn = metrics_fn\n",
        "\n",
        "    def __call__(self, y, y_pred):\n",
        "        logs = {}\n",
        "        if (self.__metrics_fn is not None):\n",
        "            for key in self.__metrics_fn.keys():\n",
        "                metric = self.__metrics_fn[key](y, y_pred)\n",
        "                logs[key] = metric\n",
        "        return logs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGAwM2WMSaxa"
      },
      "source": [
        "## Build Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UKHTFByoSdJc"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Metrics(object):\n",
        "    def __init__(self, name=\"\"):\n",
        "        \"\"\"\"\"\"\n",
        "        self.name = name\n",
        "\n",
        "    def __call__(self, y_pred, y):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2xIZWnAnU41V"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Acuracy(Metrics):\n",
        "    def __init__(self, **kw):\n",
        "        super().__init__(**kw)\n",
        "        pass\n",
        "\n",
        "    def __call__(self, y_pred, y):\n",
        "        # y_pred: logits or probabilities (batch_size, num_classes)\n",
        "        # y_true: true labels (batch_size,)\n",
        "        preds = torch.argmax(y_pred, dim=1)\n",
        "        y     = torch.argmax(y,      dim=1)\n",
        "        correct = (preds == y).sum().item()\n",
        "        total = y.size(0)\n",
        "        return correct / total\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5ucXnc8H2l_"
      },
      "source": [
        "# Build Callback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdk7L7ObSgPJ"
      },
      "source": [
        "## Build CallbacksList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iE4K8V6aH8Pk"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CallbacksList(object):\n",
        "    def __init__(self, callbacks):\n",
        "        \"\"\"\"\"\"\n",
        "        if (callbacks is not None):\n",
        "            if (isinstance(callbacks, list)):\n",
        "                    for i, callback in enumerate(callbacks, 0):\n",
        "                        if (not isinstance(callback, (type(Callbacks()), type(PlotLossesKeras())))):\n",
        "                            raise NameError(\"The callback: '{}' is type '{}' not as 'Callbacks' object\".format(i, type(callback)))\n",
        "            else:\n",
        "                raise NameError(\"The argument need to be as 'List' object, but is '{}'\".format(type(callbacks)))\n",
        "        else:\n",
        "            callbacks = []\n",
        "        #\n",
        "        self.__callbacks = callbacks\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_batch_begin(batch, logs)\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_batch_end(batch, logs)\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_epoch_begin(epoch, logs)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_epoch_end(epoch, logs)\n",
        "\n",
        "    def on_predict_batch_begin(self, batch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_predict_batch_begin(batch, logs)\n",
        "\n",
        "    def on_predict_batch_end(self, batch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_predict_batch_end(batch, logs)\n",
        "\n",
        "    def on_predict_begin(self, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_predict_begin(logs)\n",
        "\n",
        "    def on_predict_end(self, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_predict_end(logs)\n",
        "\n",
        "    def on_test_batch_begin(self, batch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_test_batch_begin(batch, logs)\n",
        "\n",
        "    def on_test_batch_end(self, batch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_test_batch_end(batch, logs)\n",
        "\n",
        "    def on_test_begin(self, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_test_begin(logs)\n",
        "\n",
        "    def on_test_end(self, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_test_end(logs)\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_train_batch_begin(batch, logs)\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_train_batch_end(batch, logs)\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_train_begin(logs)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_train_end(logs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC-Fusm36iXQ"
      },
      "source": [
        "## Build Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "t3wLdybR6ltJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Callbacks(object):\n",
        "    def __init__(self,):\n",
        "        \"\"\"\"\"\"\n",
        "        pass\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_predict_batch_begin(self, batch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_predict_batch_end(self, batch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_predict_begin(self, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_predict_end(self, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_test_batch_begin(self, batch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_test_batch_end(self, batch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_test_begin(self, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_test_end(self, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Wr49EeH1m_G"
      },
      "source": [
        "# Build Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCNgANQO5sAu"
      },
      "source": [
        "## Build Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Dda0Ro4t5uZe"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Layer(object):\n",
        "    def __init__(self, name=\"layer\"):\n",
        "        torch.set_grad_enabled(False) # do not use pythorch gradient\n",
        "        self.name = name\n",
        "        self.__parameters = []\n",
        "        self.__grads = []\n",
        "        self.__is_derivable = False\n",
        "\n",
        "    def set_is_derivable(self, bVal):\n",
        "        self.__is_derivable = bVal\n",
        "\n",
        "    def is_derivable(self):\n",
        "        return self.__is_derivable\n",
        "\n",
        "    def get_grads(self):\n",
        "        return self.__grads\n",
        "\n",
        "    def get_grad(self, arg:int):\n",
        "        return self.__grads[arg]\n",
        "\n",
        "    def _init_param(self, shape, init_fn):\n",
        "        if (init_fn is not None):\n",
        "            x = init_fn(shape)\n",
        "        else:\n",
        "            # init like glorot uniform\n",
        "            lim = np.sqrt(6/np.sum(shape))\n",
        "            x = torch.empty(*shape).uniform_(-lim, lim)\n",
        "        self.__parameters.append(x)\n",
        "        if (not self.__is_derivable):\n",
        "            self.__grads.append(torch.empty(*shape))\n",
        "        else:\n",
        "            self.__grads = None\n",
        "        return x\n",
        "\n",
        "    def backward(self, delta, featuresT):\n",
        "        raise NameError(\"Layer {}: The method 'backward' is not implemented\".format(self.name))\n",
        "\n",
        "    def get_prime(self, features):\n",
        "        raise NameError(\"Layer {}: The method 'get_prime' is not implemented\".format(self.name))\n",
        "\n",
        "    def get_weights(self):\n",
        "        raise NameError(\"Layer {}: The method 'get_weights' is not implemented\".format(self.name))\n",
        "\n",
        "    def parameters(self):\n",
        "        return self.__parameters\n",
        "\n",
        "    def to(self, device):\n",
        "        for parameters in self.__parameters:\n",
        "            parameters.to(device)\n",
        "\n",
        "    def copy(self):\n",
        "        copy_params = []\n",
        "        for param in self.__parameters:\n",
        "            c_param = torch.empty(param.size(), dtype=torch.float32)\n",
        "            c_param.copy_(param, non_blocking=False)\n",
        "            copy_params.append(c_param)\n",
        "        return copy_params\n",
        "\n",
        "    def cmp(self, parameters: list):\n",
        "        is_equal = True\n",
        "        print(\"layer {}, size: loc {}, par {}\".format(self.name, len(self.__parameters), len(parameters)))\n",
        "        for loc_parameters, c_parameters in zip(self.__parameters, parameters):\n",
        "            is_equal = is_equal and torch.allclose(loc_parameters, c_parameters)\n",
        "        return is_equal\n",
        "\n",
        "    def __call__(self, x):\n",
        "        raise NameError(\"Layer {}: The method '__call__' is not implemented\".format(self.name))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNS-o5cc697h"
      },
      "outputs": [],
      "source": [
        "test_l = Layer(name=\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STQxIDrfjGhm"
      },
      "source": [
        "## Build Input layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eivNe4zujJtZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "class InputLayer(Layer):\n",
        "    def __init__(self, **kw):\n",
        "        super().__init__(**kw)\n",
        "        self.set_is_derivable(False)\n",
        "\n",
        "    def backward(self, delta, featuresT):\n",
        "        pass\n",
        "\n",
        "    def get_prime(self, features):\n",
        "        return None\n",
        "\n",
        "    def get_weights(self):\n",
        "        return None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkCJdVkn1vwi"
      },
      "source": [
        "## Build Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "aiP-o9mjbihY"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Dense(Layer):\n",
        "    def __init__(self, in_size, out_size, init_fn=None, use_bias=False, init_fn_b=None, **kw):\n",
        "        super().__init__(**kw)\n",
        "        self.__use_bias = use_bias\n",
        "        self.weight = self._init_param((out_size, in_size), init_fn)\n",
        "        if (self.__use_bias):\n",
        "            self.bias = self._init_param((out_size, 1), init_fn_b)\n",
        "        self.set_is_derivable(False)\n",
        "\n",
        "    def backward(self, delta, featuresT):\n",
        "        \"\"\"\n",
        "        acualizarea gradientilor pentru stratul actual\n",
        "        delta - ∂L/∂z, derivata erorilor din stratul actual\n",
        "        featuresT - transpusa caracteristicilor de iesire din stratul precedent (L-1)\n",
        "        \"\"\"\n",
        "        # calculate weight gradients\n",
        "        nabla_w = torch.matmul(delta, featuresT)# w = D*Ft\n",
        "        grad_w = self.get_grad(0)\n",
        "        torch.sum(nabla_w, axis=0, out=grad_w)# w = D*Ft\n",
        "        #print(\"----nabla_w\", nabla_w.shape)\n",
        "        # calculate bias gradients\n",
        "        if (self.__use_bias):\n",
        "            grad_b = self.get_grad(1)\n",
        "            torch.sum(delta, axis=0, out=grad_b)\n",
        "            #print(\"----nabla_b\", nabla_b.shape)\n",
        "        del nabla_w\n",
        "        # Empty cached memory\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    def get_prime(self, features):\n",
        "        return None\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.weight\n",
        "\n",
        "    def __call__(self, x):\n",
        "        w = self.weight.unsqueeze(0)\n",
        "        x = torch.matmul(w, x, out=None)\n",
        "        if (self.__use_bias):\n",
        "            torch.add(x, self.bias, out=x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "SV9MIHyIb72l",
        "outputId": "f80198b6-741a-4043-cde6-6211c700138e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 100, 1])\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "transpose() received an invalid combination of arguments - got (int, int, int), but expected one of:\n * (int dim0, int dim1)\n * (name dim0, name dim1)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-928101735.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# calculate weight gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: transpose() received an invalid combination of arguments - got (int, int, int), but expected one of:\n * (int dim0, int dim1)\n * (name dim0, name dim1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "batch_size = 2\n",
        "delta    = torch.empty(batch_size, 10, 1).uniform_(-1, 1)\n",
        "features = torch.empty(batch_size, 100, 1).uniform_(-1, 1)\n",
        "print(features.shape)\n",
        "# calculate weight gradients\n",
        "t0 = torch.matmul(delta, features.transpose(-1, -2))\n",
        "t1 = torch.matmul(delta, features.transpose(0, 2, 1))\n",
        "\n",
        "torch.allclose(t0, t1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foo3FM-YepXe"
      },
      "outputs": [],
      "source": [
        "\n",
        "batch_size = 2\n",
        "\n",
        "w = torch.empty(100, 784).uniform_(-1, 1)\n",
        "b = torch.empty(100, 1).uniform_(-1, 1)\n",
        "x = torch.empty(batch_size, 784, 1).uniform_(-1, 1)\n",
        "\n",
        "# calculate weight gradients\n",
        "b_y = torch.matmul(w.unsqueeze(0), x)\n",
        "_ = torch.add(b_y, b, out=b_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42CDhf4S4Xhg",
        "outputId": "0eb8361a-940e-4879-b8f3-3cac43f62f23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "np_w = np.expand_dims(w.numpy(), axis=0)\n",
        "np_x = x.numpy()\n",
        "np_y = np.matmul(np_w, np_x)\n",
        "np_y += b.numpy()\n",
        "np.allclose(np_y, b_y.numpy(), rtol=1e-04, atol=1e-08)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7MFDFUi5Kbs",
        "outputId": "f65cfd87-2713-4849-a46a-7b60a227eb0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-6.7976947] [-6.7976933]\n"
          ]
        }
      ],
      "source": [
        "print(np_y[0][0], b_y.numpy()[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Hx2u3q3J4-nB",
        "outputId": "3c802e09-b88b-485f-e164-b0ffaf7e391c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True]],\n",
              "\n",
              "       [[False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False]]])"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np_y==b_y.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRQ-IgXz2358",
        "outputId": "522b82e0-29c7-45c4-fd4f-74d7e23d40e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([100, 1])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = torch.matmul(w, x[0])\n",
        "torch.allclose(b_y[0], y)\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU17HAIC4MG9",
        "outputId": "e37e096f-2627-4ca8-9f5a-50ab45d7e27a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bb_y = torch.add(b_y, b)\n",
        "b__y = torch.add(b_y[0], b)\n",
        "torch.allclose(bb_y[0], b__y)\n",
        "#y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-G7YogWSi5r",
        "outputId": "2fc6f5a9-85e2-4f6d-965b-de1b71545871"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.]]])\n"
          ]
        }
      ],
      "source": [
        "tmp_x = torch.empty(3, 20).uniform_(-1, 1)  # Uniform [-1, 1]\n",
        "tmp_x = torch.ones(2, 3, 20)  # Uniform [-1, 1]\n",
        "print(tmp_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxeH72pU-3xe",
        "outputId": "8064d039-215a-4eb0-ee90-2559cf2b8f1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tmp_x = torch.empty(3, 20).uniform_(-1, 1)  # Uniform [-1, 1]\n",
        "\n",
        "torch.allclose(torch.sum(tmp_x, dim=0, out=None), torch.sum(tmp_x, axis=0, out=None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOhpSQ1laMJ-"
      },
      "outputs": [],
      "source": [
        "dense_l = Dense(in_size=20, out_size=3, use_bias=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-O0adhIa5PO",
        "outputId": "60ac5c98-b8f0-41f9-e71d-c4fb1296f7de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 1.1257, -1.0865, -1.1252],\n",
              "         [ 1.1257, -1.0865, -1.1252],\n",
              "         [ 1.1257, -1.0865, -1.1252]],\n",
              "\n",
              "        [[ 1.1257, -1.0865, -1.1252],\n",
              "         [ 1.1257, -1.0865, -1.1252],\n",
              "         [ 1.1257, -1.0865, -1.1252]]])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dense_l(tmp_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "5vSJG4MJfhWS",
        "outputId": "f228bff3-508f-4d23-f4c0-f34ae9391e09"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Dense.backward() missing 1 required positional argument: 'features'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-312491865.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdense_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: Dense.backward() missing 1 required positional argument: 'features'"
          ]
        }
      ],
      "source": [
        "dense_l.backward(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUCepVut2W9u"
      },
      "source": [
        "## Build Relu layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IlG2IsMs2aoS"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Relu(Layer):\n",
        "    def __init__(self, min=0, **kw):\n",
        "        super().__init__(**kw)\n",
        "        self.__min = torch.tensor(min)\n",
        "        self.set_is_derivable(True)\n",
        "\n",
        "    def backward(self, delta, featuresT):\n",
        "        pass\n",
        "\n",
        "    def get_prime(self, features):\n",
        "        return (features > 0).float()\n",
        "\n",
        "    def get_weights(self):\n",
        "        return None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = torch.maximum(x, self.__min)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQAhto3u4GHd",
        "outputId": "e0eb7d2a-3646-407b-b820-9fe6f4a40dd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.2147,  0.7854,  0.6982,  0.7165,  0.9628, -0.0168, -0.7561, -0.0126,\n",
            "         -0.0143,  0.2169,  0.4241, -0.5057, -0.4185,  0.0529,  0.4176,  0.7627,\n",
            "          0.2612, -0.9293, -0.8287,  0.1271],\n",
            "        [ 0.0707,  0.9269, -0.8177,  0.3035, -0.4018,  0.1338, -0.4901, -0.1726,\n",
            "          0.5371, -0.8540, -0.5457,  0.8025, -0.3467, -0.2213, -0.4189, -0.5081,\n",
            "          0.8426,  0.9289,  0.8051,  0.2765],\n",
            "        [ 0.4647,  0.5800, -0.9863, -0.9222, -0.1540, -0.9986,  0.4406,  0.7460,\n",
            "          0.9229, -0.0899,  0.8097,  0.3678, -0.8543, -0.0504,  0.9877,  0.0411,\n",
            "          0.2094, -0.5094,  0.6172, -0.0490]])\n"
          ]
        }
      ],
      "source": [
        "tmp_x = torch.empty(3, 20).uniform_(-1, 1)  # Uniform [-1, 1]\n",
        "#tmp_x = torch.ones(2, 3, 20)  # Uniform [-1, 1]\n",
        "print(tmp_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEVNXQ-M4qqG"
      },
      "outputs": [],
      "source": [
        "relu_l = Relu(min=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Fxqjc074wYh",
        "outputId": "4993a18c-5a38-46e9-d679-6b57bab57836"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 20])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "relu_l(tmp_x).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "6c66vNb34_1D",
        "outputId": "abe241c0-5ede-46de-bf39-90e9d82eec15"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Relu.get_prime() missing 1 required positional argument: 'features'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3436263032.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrelu_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: Relu.get_prime() missing 1 required positional argument: 'features'"
          ]
        }
      ],
      "source": [
        "relu_l.get_prime().shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OVh9YZo02Fl"
      },
      "source": [
        "## Build softmax layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fQJ6gc607ig"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Softmax(Layer):\n",
        "    def __init__(self, **kw):\n",
        "        super().__init__(**kw)\n",
        "        self.set_is_derivable(True)\n",
        "\n",
        "    def backward(self, delta, featuresT):\n",
        "        pass\n",
        "    \"\"\"\n",
        "    def get_prime(self, features):\n",
        "        # Suppose softmax over channel dim\n",
        "        x = self(features)\n",
        "        x_flat = x.reshape(-1, x.shape[-1])  # collapse batch*H*W into one dimension\n",
        "        # batch matrix multiplication\n",
        "        x_bmm = torch.bmm(x_flat.unsqueeze(2), x_flat.unsqueeze(1))\n",
        "        jacobian = torch.diag_embed(x_flat) - x_bmm\n",
        "        jacobian = jacobian.sum(dim=-1, keepdim=False)\n",
        "        return jacobian\n",
        "    \"\"\"\n",
        "\n",
        "    def get_prime(self, features):\n",
        "        # Suppose softmax over channel dim\n",
        "        x = self(features)\n",
        "        diff = torch.sub(1, x, alpha=1, out=None)\n",
        "        x = torch.mul(x, diff, out=x)\n",
        "        return x\n",
        "\n",
        "    def get_weights(self):\n",
        "        return None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = torch.exp(x) - torch.max(x)\n",
        "        x = torch.div(x, torch.sum(x), rounding_mode=None, out=None)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-U3hComzdPl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99z6B2iC4bAD",
        "outputId": "07a9fbe2-ce17-48a2-ddf0-fbafc2409c28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.2362,  0.4914, -0.5989,  0.5817, -0.1990, -0.4743, -0.4052, -0.5721,\n",
            "          0.0346, -0.3257,  0.3997,  0.9869, -0.1369,  0.8468,  0.2440,  0.3187,\n",
            "         -0.3427, -0.2786, -0.9753, -0.3535],\n",
            "        [-0.1218,  0.8696,  0.6346,  0.7159, -0.5462, -0.9119,  0.3980, -0.8161,\n",
            "          0.9467,  0.3217,  0.0708,  0.0147, -0.8290,  0.4878,  0.3823, -0.3581,\n",
            "          0.4144,  0.1264,  0.9421,  0.5322],\n",
            "        [ 0.3252, -0.3648, -0.1405,  0.1632,  0.5896,  0.5241,  0.5790,  0.4439,\n",
            "          0.2877, -0.9869, -0.6017, -0.8320, -0.1324,  0.5844,  0.8483, -0.0297,\n",
            "         -0.5137, -0.4017, -0.3747, -0.6301]])\n"
          ]
        }
      ],
      "source": [
        "tmp_x = torch.empty(3, 20).uniform_(-1, 1)  # Uniform [-1, 1]\n",
        "#tmp_x = torch.ones(2, 3, 20)  # Uniform [-1, 1]\n",
        "print(tmp_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1UPSCAa4dOX"
      },
      "outputs": [],
      "source": [
        "softmax_l = Softmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMg6M0e_4hNI",
        "outputId": "66582ad2-0bb1-4147-f2e6-0e6e11463ffb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0111, 0.0230, 0.0077, 0.0251, 0.0115, 0.0087, 0.0094, 0.0079, 0.0145,\n",
              "         0.0101, 0.0210, 0.0377, 0.0123, 0.0328, 0.0179, 0.0193, 0.0100, 0.0106,\n",
              "         0.0053, 0.0099],\n",
              "        [0.0124, 0.0335, 0.0265, 0.0287, 0.0081, 0.0056, 0.0209, 0.0062, 0.0362,\n",
              "         0.0194, 0.0151, 0.0143, 0.0061, 0.0229, 0.0206, 0.0098, 0.0213, 0.0159,\n",
              "         0.0360, 0.0239],\n",
              "        [0.0194, 0.0098, 0.0122, 0.0165, 0.0253, 0.0237, 0.0251, 0.0219, 0.0187,\n",
              "         0.0052, 0.0077, 0.0061, 0.0123, 0.0252, 0.0328, 0.0136, 0.0084, 0.0094,\n",
              "         0.0097, 0.0075]])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "softmax_l(tmp_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyWu3Uqu4ohv",
        "outputId": "76b1c6b8-5868-4008-b6f4-b468117dae2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 20, 20])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "softmax_l.get_prime().shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CifUve92TEZ-"
      },
      "source": [
        "## Build sigmoid layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IUmoei9uTE1A"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Sigmoid(Layer):\n",
        "    def __init__(self, **kw):\n",
        "        super().__init__(**kw)\n",
        "        self.__t = torch.tensor(1.)\n",
        "        self.set_is_derivable(True)\n",
        "\n",
        "    def backward(self, delta, featuresT):\n",
        "        pass\n",
        "\n",
        "    def get_prime(self, features):\n",
        "        # Suppose softmax over channel dim\n",
        "        x = self(features)\n",
        "        diff = torch.sub(self.__t, x, alpha=1, out=None)\n",
        "        x = torch.mul(x, diff, out=None)\n",
        "        return x\n",
        "\n",
        "    def get_weights(self):\n",
        "        return None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = torch.exp(-x, out=None)# se aloca memorie noua pentru functia de activare\n",
        "        x = torch.add(x, 1., alpha=1, out=None)\n",
        "        x = torch.div(1., x, out=None)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QT0wNGq1udy"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JH_jOksz4Yd8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "A module to implement the stochastic gradient descent learning\n",
        "algorithm for a feedforward neural network.  Gradients are calculated\n",
        "using backpropagation.  Note that I have focused on making the code\n",
        "simple, easily readable, and easily modifiable.  It is not optimized,\n",
        "and omits many desirable features.\n",
        "\"\"\"\n",
        "\n",
        "class Model(object):\n",
        "    def __init__(self, device, dtype=torch.float32):\n",
        "        \"\"\"\"\"\"\n",
        "        self.__device = device\n",
        "        self.dtype = dtype\n",
        "        self.__layers = []\n",
        "        self.__parameteres  = None\n",
        "        self.__grads        = None\n",
        "        self.__out_features = []\n",
        "        self.__layers_size  = 0\n",
        "\n",
        "    def Sequential(self, layers: list):\n",
        "        if (isinstance(layers, list)):\n",
        "            for i, layer in enumerate(layers, 0):\n",
        "                if (not isinstance(layer, Layer)):\n",
        "                    raise NameError(\"The layer: '{}' is not as 'Layer' object\".format(i))\n",
        "                else:\n",
        "                    layer.to(self.__device)\n",
        "            self.__layers = layers\n",
        "            self.__layers_size  = len(self.__layers)\n",
        "        else:\n",
        "            raise NameError(\"The argument need to be as 'List' object, but is '{}'\".format(type(layers)))\n",
        "\n",
        "    def compile(self, optimizer, loss, metrics, callbacks):\n",
        "        self.optimizer = optimizer\n",
        "        self.loss_fn = loss\n",
        "        self.metric_fn = MetricsList(metrics)\n",
        "        self.callbacks = CallbacksList(callbacks)\n",
        "\n",
        "    def __get_not_derivable_layer(self, arg:int):\n",
        "        if (arg <= 0):\n",
        "            arg += self.__layers_size\n",
        "        if (arg < 0):\n",
        "            arg = self.__layers_size\n",
        "        while (arg < self.__layers_size):\n",
        "            layer = self.__layers[arg]\n",
        "            if (not layer.is_derivable()):\n",
        "                break\n",
        "            else:\n",
        "                arg += 1\n",
        "        else:\n",
        "            arg = -1\n",
        "        return arg\n",
        "\n",
        "    def virtual_backward(self, loss, data):\n",
        "        for x, y in data:\n",
        "            x = x.to(self.__device)\n",
        "            y_pred = self(x)\n",
        "        # prepare loss\n",
        "        if (loss is not None):\n",
        "            loss = torch.from_numpy(loss)\n",
        "        else:\n",
        "            loss = self.loss_fn(y_pred, y)\n",
        "        return self.virtual_backward_graph(loss)\n",
        "\n",
        "    def virtual_backward_graph(self, loss):\n",
        "        \"\"\"Crearea unui graf de executie optimizat pentru calcularea gradientilor\n",
        "        loss - devierile de la functia de eticheta\n",
        "        graph_execution - lista finala de executie, pentru a face propagare inversa\n",
        "                        pozitia [0]    - rezervata pentru loss\n",
        "                        pozitiile [1:] - graful de calculare a gradientilor optimizat\n",
        "        \"\"\"\n",
        "        graph_execution = []\n",
        "        # prepare loss\n",
        "        if ((loss.ndim == 0) or ((loss.ndim == 1) and (loss.shape[-1] == 1))):\n",
        "            features = self.__out_features[-1]\n",
        "            # fill all outputs to calculate gradients\n",
        "            delta = torch.full(features.shape, fill_value=loss, dtype=self.dtype)\n",
        "            graph_execution.append({\"loss\":True})\n",
        "        else:\n",
        "            delta = loss\n",
        "            graph_execution.append({\"loss\":False})\n",
        "        print(\"loss: {}, type {}\".format(delta.shape, type(delta)))\n",
        "        # backprop\n",
        "        prime_fn = None\n",
        "        for l in range(1, self.__layers_size, 1):\n",
        "            layer = self.__layers[-l]\n",
        "            print(\"+++layer: {}\".format(layer.name))\n",
        "            # if is derivable do not have learnable parameters\n",
        "            if (layer.is_derivable()):\n",
        "                # do inherit, derivative function for next 'back layer' layer-1\n",
        "                print(\"\\tlayer {}, '{}'\".format(layer.name, \"derivable\"))\n",
        "                prime_fn = layer.get_prime\n",
        "            else:\n",
        "                graph_execution.append({\"layer\":(layer.name, -l)})\n",
        "                # do not inherit, derivative function from previous layer\n",
        "                # back propagation\n",
        "                # get trainable layer\n",
        "                arg = self.__get_not_derivable_layer(-l+1)\n",
        "                print(\"\\t__weights arg {}\".format(arg))\n",
        "                if (arg >= 0): # next layer is not derivable (Dense, )\n",
        "                    weights = self.__layers[arg].get_weights()\n",
        "                    weights = weights.transpose(1, 0).unsqueeze(0)\n",
        "                    print(\"\\tWt@D layer {}\".format(self.__layers[arg].name))\n",
        "                    print(\"\\tWt@D shape: 'weights' {}, 'delta' {}\".format(weights.shape, delta.shape))\n",
        "                    delta   = torch.matmul(weights, delta)\n",
        "                    print(\"\\tWt@D shape: 'new delta' {}\".format(delta.shape))\n",
        "                    graph_execution[-1].update({\"Wt\":(self.__layers[arg].name, arg)})\n",
        "                else:\n",
        "                    graph_execution[-1].update({\"Wt\":(None, -1)})\n",
        "                # check if next layer is derivable,\n",
        "                # if is derivable inherit prime function\n",
        "                # if not derivable do not multiply by actual layer derivate\n",
        "                if (prime_fn is not None): # next layer is derivable (Sigmoid, Relu)\n",
        "                    # Derivative of the last layer\n",
        "                    # calculate gradients for layer-l\n",
        "                    features = self.__out_features[-l]\n",
        "                    prime = prime_fn(features)\n",
        "                    delta = torch.mul(delta, prime)\n",
        "                    print(\"\\tactive func: {}\".format(self.__layers[-l+1].name))\n",
        "                    print(\"\\tactive func: D*P shape: 'delta' {}, 'prime' {}\".format(delta.shape, features.shape))\n",
        "                    graph_execution[-1].update({\"active_func\":(self.__layers[-l+1].name, prime_fn)})\n",
        "                    prime_fn = None\n",
        "                else:\n",
        "                    graph_execution[-1].update({\"active_func\":(None, None)})\n",
        "                # calculate gradients for layer -l\n",
        "                features = self.__out_features[-l-1].transpose(-1, -2)\n",
        "                graph_execution[-1].update({\"prev_feature\":(self.__layers[-l-1].name, -l-1)})\n",
        "                print(\"\\tgrad;W=D*Ft prev_feature {}\".format(self.__layers[-l-1].name))\n",
        "                print(\"\\tgrad;W=D*Ft: delta {}, features {}\".format(delta.shape, features.shape))\n",
        "        del delta\n",
        "        del features\n",
        "        del prime\n",
        "        del prime_fn\n",
        "        return graph_execution\n",
        "        # end backward\n",
        "\n",
        "\n",
        "    def backward(self, loss):\n",
        "        \"\"\"Actualizeaza gradientii pentru fiecare parametru antrenabil din fiecare strat\n",
        "        loss - devierile de la functia de eticheta\n",
        "        graph_execution - lista finala de executie, pentru a face propagare inversa\n",
        "                        pozitia [0]    - rezervata pentru loss\n",
        "                        pozitiile [1:] - graful de calculare a gradientilor optimizat\n",
        "        \"\"\"\n",
        "        #\n",
        "        if (self.graph_execution[0][\"loss\"]):\n",
        "            features = self.__out_features[-1]\n",
        "            # fill all outputs to calculate gradients\n",
        "            delta = torch.full(features.shape, fill_value=loss, dtype=self.dtype)\n",
        "        else:\n",
        "            delta = loss\n",
        "        # aplica graful de executie\n",
        "        for g_execution in self.graph_execution[1:]:\n",
        "            arg_layer = g_execution[\"layer\"][1]\n",
        "            arg_w     = g_execution[\"Wt\"][1]\n",
        "            prime_fn  = g_execution[\"active_func\"][1]\n",
        "            arg_prev_feature = g_execution[\"prev_feature\"][1]\n",
        "            # obtine stratul propagare inversa\n",
        "            layer = self.__layers[arg_layer]\n",
        "            # actualizeaza delta (∂L/∂z)\n",
        "            if (arg_w > 0): # next layer is not derivable (Dense, )\n",
        "                weights = self.__layers[arg_w].get_weights()\n",
        "                weights = weights.transpose(1, 0).unsqueeze(0)\n",
        "                delta   = torch.matmul(weights, delta)\n",
        "                del weights\n",
        "            # aplica derivata functiei de activare\n",
        "            if (prime_fn is not None): # next layer is derivable (Sigmoid, Relu)\n",
        "                features = self.__out_features[arg_layer]\n",
        "                prime = prime_fn(features)\n",
        "                delta = torch.mul(delta, prime)\n",
        "                del prime\n",
        "                del features\n",
        "            # calculeaza gradientul pentru parametrii din acest strat\n",
        "            features = self.__out_features[arg_prev_feature].transpose(-1, -2)\n",
        "            layer.backward(delta, features)\n",
        "            del features\n",
        "        del delta\n",
        "        # Empty cached memory\n",
        "        #torch.cuda.empty_cache()\n",
        "        # end backward\n",
        "\n",
        "    def get_grads(self):\n",
        "        if (self.__grads is None):\n",
        "            self.__grads = []\n",
        "            for layer in self.__layers:\n",
        "                self.__grads.append(layer.get_grads())\n",
        "        return self.__grads\n",
        "\n",
        "    def parameters(self):\n",
        "        if (self.__parameteres is None):\n",
        "            self.__parameteres = []\n",
        "            for layer in self.__layers:\n",
        "                self.__parameteres.append(layer.parameters())\n",
        "        return self.__parameteres\n",
        "\n",
        "    def forward(self, train_ds, test_ds=None, epochs=1):\n",
        "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
        "        if (not isinstance(train_ds, DataLoader)):\n",
        "            raise NameError(\"The train dataset: is type '{}' not as 'DataLoader' object\".format(type(train_ds)))\n",
        "        # do graph_backward operation\n",
        "        self.graph_execution = self.virtual_backward(loss=None, data=train_ds.take(1))\n",
        "        # start training\n",
        "        self.callbacks.on_train_begin()\n",
        "        for epoch in range(epochs):\n",
        "            epoch_logs = self.train_batch(epoch, train_ds)\n",
        "        self.callbacks.on_train_end(epoch_logs)\n",
        "        del self.graph_execution\n",
        "        return None\n",
        "\n",
        "    def train_batch(self, epoch, train_ds):\n",
        "        self.callbacks.on_epoch_begin(epoch)\n",
        "        batch_logs = {}\n",
        "        for i, data in zip(range(len(train_ds)), train_ds()):\n",
        "            self.callbacks.on_train_batch_begin(i)\n",
        "            batch_logs = self.train_step(data)\n",
        "            self.callbacks.on_train_batch_end(i, batch_logs)\n",
        "        self.callbacks.on_epoch_end(epoch, batch_logs)\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "        #print(\"type x {}\".format(type(x)))\n",
        "        x = x.to(self.__device)\n",
        "        y = y.to(self.__device)\n",
        "        y_pred = self(x)\n",
        "        #print(\"y_pred {}, y {}\".format(y_pred.shape, y.shape))\n",
        "        loss = self.loss_fn(y_pred, y)\n",
        "        #print(\"loss {}, data @{}@\".format(loss.shape, loss))\n",
        "        metrics = self.metric_fn(y_pred, y)\n",
        "        self.backward(loss)\n",
        "        grads = self.get_grads()\n",
        "        self.optimizer(grads, x.shape[0])\n",
        "        loss = torch.mean(loss)\n",
        "        logs = {\"loss\":loss}\n",
        "        logs.update(metrics)\n",
        "        return logs\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        del self.__out_features\n",
        "        # Empty cached memory\n",
        "        torch.cuda.empty_cache()\n",
        "        # save input for gradient calculation\n",
        "        self.__out_features = [inputs]\n",
        "        y = inputs\n",
        "        #print(\"model: shape {}\".format(y.shape))\n",
        "        for layer in self.__layers:\n",
        "            y = layer(y)\n",
        "            #print(\"model: name {}, shape {}\".format(layer.name, y.shape))\n",
        "            self.__out_features.append(y)\n",
        "        return y\n",
        "\n",
        "    def copy(self):\n",
        "        parameteres = []\n",
        "        for layer in self.__layers:\n",
        "            parameteres.append(layer.copy())\n",
        "        return parameteres\n",
        "\n",
        "    def cmp(self, m_parameters):\n",
        "        is_equal = True\n",
        "        for layer, l_parameters in zip(self.__layers, m_parameters):\n",
        "            tmp_equal = layer.cmp(l_parameters)\n",
        "            print(\"layer {}, cmp {}\".format(layer.name, tmp_equal))\n",
        "            is_equal = is_equal and tmp_equal\n",
        "        return is_equal\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "        \"\"\"Return the number of test inputs for which the neural\n",
        "        network outputs the correct result. Note that the neural\n",
        "        network's output is assumed to be the index of whichever\n",
        "        neuron in the final layer has the highest activation.\"\"\"\n",
        "        test_results = [(np.argmax(self.feedforward(x)), y)\n",
        "                        for (x, y) in test_data]\n",
        "        return sum(int(x == y) for (x, y) in test_results)\n",
        "\n",
        "    def cost_derivative(self, output_activations, y):\n",
        "        \"\"\"Return the vector of partial derivatives partial C_x\n",
        "        partial a for the output activations.\"\"\"\n",
        "        return (output_activations-y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgSZo_cFavJv"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_not_derivable_layer(arg:int, lst):\n",
        "    if (arg <= 0):\n",
        "        arg += len(lst)\n",
        "    if (arg < 0):\n",
        "        arg = len(lst)\n",
        "    while (arg < len(lst)):\n",
        "        if (not lst[arg]):\n",
        "            break\n",
        "        else:\n",
        "            arg += 1\n",
        "    else:\n",
        "        arg = -1\n",
        "    return arg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlF7ijfqbCHH",
        "outputId": "41e83326-0a83-4659-a561-f6f2471d6ca0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_not_derivable_layer(2, [0, 0, 1, 0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHI_6IyE4Yay",
        "outputId": "43517622-652c-48a2-e799-014a03f271e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.]]])\n"
          ]
        }
      ],
      "source": [
        "tmp_x = torch.ones(2, 3, 20)  # Uniform [-1, 1]\n",
        "print(tmp_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2JcAsVA4YXS",
        "outputId": "e25cf740-dd2f-4f39-ecca-b7ee90e2ae7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 20, 3])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tmp_x.transpose(2, 1).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXc4vD9GdCvn"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "J3XwtU2uc8so"
      },
      "outputs": [],
      "source": [
        "\n",
        "BATCH_SIZE = 32\n",
        "# Pipiline\n",
        "train_ds = ExtendedMNISTDataset(root=\"/content\", train=True)\n",
        "test_ds  = ExtendedMNISTDataset(root=\"/content\", train=False)\n",
        "# Data loader\n",
        "train_loader = DataLoader(train_ds, batchsize=BATCH_SIZE, shuffle=True)\n",
        "train_loader.map(lambda x, y: (normalization_n1_p1(x), one_hot(y, num_classes=10)))\n",
        "train_loader.map(lambda x, y: (x.unsqueeze(-1), y.unsqueeze(-1)))\n",
        "\n",
        "test_loader  = DataLoader(test_ds,  batchsize=20, shuffle=False)\n",
        "test_loader.map(lambda x, y: (normalization_n1_p1(x), one_hot(y, num_classes=10)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qq0Ft24dTZ9",
        "outputId": "9b40f665-d8b2-48e1-ece9-62efc71b247c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if torch.accelerator.is_available():\n",
        "    device=torch.accelerator.current_accelerator()\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V07jRYzombR"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "BjvLDYmfCmKK"
      },
      "outputs": [],
      "source": [
        "def pyTorch_init(shape):\n",
        "    lim = np.sqrt(1./shape[0])\n",
        "    return torch.empty(*shape).uniform_(-lim, lim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxgOFnw6C-8Z",
        "outputId": "4e2059af-b9ce-406c-c75d-e160c2ce0c1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.0339,  0.0238, -0.0101,  ..., -0.0198, -0.0303, -0.0088],\n",
              "        [ 0.0264, -0.0121,  0.0228,  ...,  0.0283,  0.0201, -0.0348],\n",
              "        [-0.0028,  0.0025, -0.0222,  ...,  0.0340, -0.0320, -0.0116],\n",
              "        ...,\n",
              "        [-0.0238, -0.0175,  0.0106,  ...,  0.0024, -0.0053,  0.0039],\n",
              "        [ 0.0184, -0.0246, -0.0180,  ..., -0.0145,  0.0115,  0.0333],\n",
              "        [-0.0028, -0.0276, -0.0267,  ..., -0.0046,  0.0317,  0.0216]])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pyTorch_init((784, 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2Rl5P8u8ex62"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = Model(device=device)\n",
        "layers = [\n",
        "    InputLayer(name=\"Input\"),\n",
        "    Dense(784, 100, init_fn=pyTorch_init, use_bias=True, init_fn_b=pyTorch_init, name=\"Dense_h1\"),\n",
        "    #Relu(name=\"Relu_h1\"),\n",
        "    Sigmoid(name=\"Sigmoid_h1\"),\n",
        "    Dense(100, 10, init_fn=pyTorch_init, use_bias=True, init_fn_b=pyTorch_init, name=\"Dense_h2\"),\n",
        "    #Relu(name=\"Relu_h2\"),\n",
        "    Sigmoid(name=\"Sigmoid_h2\"),\n",
        "    #Dense(10, 10, init_fn=None, use_bias=False, init_fn_b=None, name=\"Dense_h3\"),\n",
        "    #Sigmoid(name=\"Sigmoid_h3\"),\n",
        "]\n",
        "model.Sequential(layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_2fDOpqWxH7",
        "outputId": "e70b68cf-5b47-4812-93bc-20fe765afc23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 784, 1])"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x, y = next(train_loader.take(1))\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5UFnr6yh3rz",
        "outputId": "89468ee4-5cc1-4e5a-dc8a-96fd482c669c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: torch.Size([32, 10, 1]), type <class 'torch.Tensor'>\n",
            "+++layer: Sigmoid_h2\n",
            "\tlayer Sigmoid_h2, 'derivable'\n",
            "+++layer: Dense_h2\n",
            "\t__weights arg -1\n",
            "\tactive func: Sigmoid_h2\n",
            "\tactive func: D*P shape: 'delta' torch.Size([32, 10, 1]), 'prime' torch.Size([32, 10, 1])\n",
            "\tgrad;W=D*Ft prev_feature Sigmoid_h1\n",
            "\tgrad;W=D*Ft: delta torch.Size([32, 10, 1]), features torch.Size([32, 1, 100])\n",
            "+++layer: Sigmoid_h1\n",
            "\tlayer Sigmoid_h1, 'derivable'\n",
            "+++layer: Dense_h1\n",
            "\t__weights arg 3\n",
            "\tWt@D layer Dense_h2\n",
            "\tWt@D shape: 'weights' torch.Size([1, 100, 10]), 'delta' torch.Size([32, 10, 1])\n",
            "\tWt@D shape: 'new delta' torch.Size([32, 100, 1])\n",
            "\tactive func: Sigmoid_h1\n",
            "\tactive func: D*P shape: 'delta' torch.Size([32, 100, 1]), 'prime' torch.Size([32, 100, 1])\n",
            "\tgrad;W=D*Ft prev_feature Input\n",
            "\tgrad;W=D*Ft: delta torch.Size([32, 100, 1]), features torch.Size([32, 1, 784])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'loss': True},\n",
              " {'layer': ('Dense_h2', -2),\n",
              "  'Wt': (None, -1),\n",
              "  'active_func': ('Sigmoid_h2',\n",
              "   <bound method Sigmoid.get_prime of <__main__.Sigmoid object at 0x7ea5143c0890>>),\n",
              "  'prev_feature': ('Sigmoid_h1', -3)},\n",
              " {'layer': ('Dense_h1', -4),\n",
              "  'Wt': ('Dense_h2', 3),\n",
              "  'active_func': ('Sigmoid_h1',\n",
              "   <bound method Sigmoid.get_prime of <__main__.Sigmoid object at 0x7ea6141aa3c0>>),\n",
              "  'prev_feature': ('Input', -5)}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "\n",
        "loss = np.array(1., dtype=np.float32)\n",
        "model.virtual_backward(loss, train_loader.take(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGJDuTWu59nk"
      },
      "outputs": [],
      "source": [
        "c_model = model.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHxve_ij69D9",
        "outputId": "47cac4ae-26c8-493e-8c62-4dc686c5a4e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer Input, size: loc 0, par 0\n",
            "layer Input, cmp True\n",
            "layer Dense_h1, size: loc 2, par 2\n",
            "layer Dense_h1, cmp True\n",
            "layer Relu_h1, size: loc 0, par 0\n",
            "layer Relu_h1, cmp True\n",
            "layer Dense_h2, size: loc 2, par 2\n",
            "layer Dense_h2, cmp True\n",
            "layer Dense_h3, size: loc 1, par 1\n",
            "layer Dense_h3, cmp True\n",
            "layer Sigmoid_h3, size: loc 0, par 0\n",
            "layer Sigmoid_h3, cmp True\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.cmp(c_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vadvn2V7Gto2"
      },
      "outputs": [],
      "source": [
        "def cost_derivative(output_activations, y):\n",
        "    \"\"\"Return the vector of partial derivatives partial C_x\n",
        "    partial a for the output activations.\"\"\"\n",
        "    return (output_activations-y)**2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gNj4zczfbHl"
      },
      "outputs": [],
      "source": [
        "\n",
        "#cros_entropy = torch.nn.CrossEntropyLoss()\n",
        "#cros_entropy = F.cross_entropy\n",
        "optimizer = SGD(model.parameters(), lr=0.001)\n",
        "plot_losses = PlotLossesKeras()\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=cost_derivative,\n",
        "    metrics={\"acuracy\":Acuracy(name=\"acuracy\")},\n",
        "    callbacks=[\n",
        "                plot_losses\n",
        "            ],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 876
        },
        "id": "-Ul0nrBehP2Y",
        "outputId": "9f1bd511-1c3f-40e3-c07f-5f382094b10a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acuracy\n",
            "\tacuracy          \t (min:    0.000, max:    0.000, cur:    0.000)\n",
            "Loss\n",
            "\tloss             \t (min:    0.094, max:    0.100, cur:    0.100)\n"
          ]
        }
      ],
      "source": [
        "model.forward(train_loader, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJupY-AF91To",
        "outputId": "5c0b05f3-42d5-4a3b-d419-0cb0d36b3308"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer Dense_h1, size: loc 2, par 2\n",
            "layer Dense_h1, cmp False\n",
            "layer Sigmoid_h1, size: loc 0, par 0\n",
            "layer Sigmoid_h1, cmp True\n",
            "layer Dense_h2, size: loc 2, par 2\n",
            "layer Dense_h2, cmp False\n",
            "layer Sigmoid_h2, size: loc 0, par 0\n",
            "layer Sigmoid_h2, cmp True\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.cmp(c_model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "x55A6JvfHaAK",
        "4xQA0TbS9iJz",
        "MavX5UXd_jqX",
        "-gsQ54N4Hy2Y",
        "Yp35IrNCH1ED",
        "B6JV4BsOHsBz",
        "-9nd7JEAH2aC",
        "G8aGDKmc9tzF",
        "UVslqY8VHz_V",
        "AW3g5UadSVzk",
        "YGAwM2WMSaxa",
        "o5ucXnc8H2l_",
        "pdk7L7ObSgPJ",
        "rC-Fusm36iXQ",
        "kCNgANQO5sAu",
        "STQxIDrfjGhm",
        "kkCJdVkn1vwi",
        "hUCepVut2W9u",
        "-OVh9YZo02Fl",
        "CifUve92TEZ-"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}