{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "x55A6JvfHaAK",
        "4xQA0TbS9iJz",
        "-gsQ54N4Hy2Y",
        "Yp35IrNCH1ED",
        "B6JV4BsOHsBz",
        "-9nd7JEAH2aC",
        "G8aGDKmc9tzF",
        "UVslqY8VHz_V",
        "AW3g5UadSVzk",
        "YGAwM2WMSaxa",
        "o5ucXnc8H2l_",
        "pdk7L7ObSgPJ",
        "rC-Fusm36iXQ",
        "kCNgANQO5sAu",
        "STQxIDrfjGhm",
        "kkCJdVkn1vwi",
        "hUCepVut2W9u"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install"
      ],
      "metadata": {
        "id": "x55A6JvfHaAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install livelossplot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG8McvlDHd8u",
        "outputId": "5868f718-4dec-41ff-d120-1a384ad14eed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.12/dist-packages (0.5.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from livelossplot) (3.10.0)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.12/dist-packages (from livelossplot) (3.7.3)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (3.1.6)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (1.3.3)\n",
            "Requirement already satisfied: narwhals>=1.13 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (2.0.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (25.0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (2.2.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (11.3.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (6.0.3)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (6.4.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.12/dist-packages (from bokeh->livelossplot) (2025.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->livelossplot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->livelossplot) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->livelossplot) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->livelossplot) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->livelossplot) (2.9.0.post0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (3.0.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "4xQA0TbS9iJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torch\n",
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import traceback\n",
        "from pathlib import Path\n",
        "from livelossplot import PlotLossesKeras\n",
        "\n",
        "# You are not allowed to use DataLoader, torch.nn, torch.functional, torchvision\n",
        "# Backpropagation and data preprocessing must be implemented from scratch\n",
        "# Check https://github.com/Tensor-Reloaded/AI-Learning-Hub/blob/main/how_to/use_kaggle.md for learning how to use kaggle and submit to this competition"
      ],
      "metadata": {
        "id": "JnlB_3F-4Ypz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data aquisition"
      ],
      "metadata": {
        "id": "MavX5UXd_jqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesing functions"
      ],
      "metadata": {
        "id": "-gsQ54N4Hy2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def normalization_n1_p1(x):\n",
        "    return (x/127.5)-1\n",
        "\n",
        "def normalization_n0_p1(x):\n",
        "    return x/255\n",
        "\n",
        "def one_hot(y, num_classes=1):\n",
        "    #print(y.shape, y)\n",
        "    tmp = torch.zeros((y.size(0), num_classes), dtype=torch.float32)\n",
        "    tmp[torch.arange(y.size(0)), y] = 1.0\n",
        "    return tmp\n"
      ],
      "metadata": {
        "id": "a3sb7JXDHzWh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary function"
      ],
      "metadata": {
        "id": "Yp35IrNCH1ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_dataset_fn(img, label):\n",
        "    info_str = \"\"\"img: shape {}, min {}, max {}, type {};\n",
        "label: shape {}, min {}, max {}, type {};\"\"\".format(img.shape, torch.min(img), torch.max(img), type(img),\n",
        "                                           label.shape, torch.min(label), torch.max(label), type(label))\n",
        "    print(info_str)"
      ],
      "metadata": {
        "id": "O8ajvvlBH6TJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "B6JV4BsOHsBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ExtendedMNISTDataset(Dataset):\n",
        "    def __init__(self, root: str = \"/kaggle/input/fii-atnn-2025-competition-1\", train: bool = True):\n",
        "        \"\"\"ExtendedMNISTDataset:\n",
        "        root  - path root of dataset\n",
        "        train - read train or test dataset (true - train, false - test)\n",
        "        preprocessing - image preprocesing function\n",
        "        Dataset structure:\n",
        "            list -> (batchsize, tuple -> (np.array -> (image->(784, )), scalar -> (labels->1)))\n",
        "        \"\"\"\n",
        "        # select filename\n",
        "        if (train):\n",
        "            file = \"extended_mnist_train.pkl\"\n",
        "        else:\n",
        "            file = \"extended_mnist_test.pkl\"\n",
        "        # join root to filename\n",
        "        filename = os.path.join(root, file)\n",
        "        # read dataset\n",
        "        dataset = self.__read(filename)\n",
        "        self.inputs, self.outputs = self.__split_data(dataset)\n",
        "\n",
        "    def __read(self, filename):\n",
        "        # try to open filename\n",
        "        try:\n",
        "            f = open(filename, \"rb\")\n",
        "            try:\n",
        "                dataset = pickle.load(f)\n",
        "            except Exception as e:\n",
        "                dataset = None\n",
        "                self.__show_exception(e)\n",
        "            finally:\n",
        "                f.close()\n",
        "        except IOError as e:\n",
        "            dataset = None\n",
        "            self.__show_exception(e)\n",
        "        return dataset\n",
        "\n",
        "    def __show_exception(self, e) -> None:\n",
        "        tb = traceback.extract_tb(e.__traceback__)\n",
        "        last_call = tb[-1]\n",
        "        print(f\"❌ Error in function '{last_call.name}' at line {last_call.lineno}\")\n",
        "        print(f\"   File: {last_call.filename}\")\n",
        "        print(f\"   Exception: {e}\")\n",
        "\n",
        "    def __split_data(self, dataset):\n",
        "        inputs  = []\n",
        "        outputs = []\n",
        "        for input, ouput in dataset:\n",
        "            inputs.append(input)\n",
        "            outputs.append(ouput)\n",
        "        return np.array(inputs, dtype=np.uint8), np.array(outputs, dtype=np.int32)\n",
        "\n",
        "    def __len__(self, ) -> int:\n",
        "        return self.inputs.shape[0]\n",
        "\n",
        "    def __getitem__(self, i : int):# int|np array\n",
        "        return self.inputs[i], self.outputs[i]\n"
      ],
      "metadata": {
        "id": "JPQpvpRF_mM3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "train_ds = ExtendedMNISTDataset(root=\"/content\", train=True)"
      ],
      "metadata": {
        "id": "s0FzmsLLAw8Y"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[[0, 1, 2]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqLrmx1JpUVq",
        "outputId": "f19073b7-2f3f-4263-f028-93687a9b1319"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
              " array([2, 6, 2], dtype=int32))"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHe3TjK9nCSB",
        "outputId": "08a3f47b-6e83-437b-d05d-bc63ef835e95"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, y = train_ds[np.arange(len(train_ds))]"
      ],
      "metadata": {
        "id": "HC5GijsbnFdW"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl_Zz0uhndHc",
        "outputId": "61ce7564-fa99-4298-a11a-c2a5f361917b"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int32(9)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "-9nd7JEAH2aC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DataLoader(object):\n",
        "    def __init__(self, dataset, batchsize=1, shuffle=False):\n",
        "        assert (batchsize > 0), \"batchsize should be ghreat than 'zero'\"\n",
        "        assert (isinstance(shuffle, bool)), \"shuffle should be 'bool'\"\n",
        "        self.dataset = dataset\n",
        "        self.batchsize = batchsize\n",
        "        self.shuffle = shuffle\n",
        "        self.size = len(self.dataset)\n",
        "        # shufle\n",
        "        if (self.shuffle):\n",
        "            self.permutation = np.random.permutation(self.size)\n",
        "        else:\n",
        "            self.permutation = np.arange(self.size, dtype=np.int32)\n",
        "        self.maps_fn = []\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.dataset)//self.batchsize\n",
        "\n",
        "    def __call__(self):\n",
        "        try:\n",
        "            for i in range(0, self.size, self.batchsize):\n",
        "                pos  = self.permutation[i:i+self.batchsize]\n",
        "                datas = self.dataset[pos]\n",
        "                if (isinstance(datas, tuple)):\n",
        "                    datas = [torch.from_numpy(data) for data in datas]\n",
        "                else:\n",
        "                    datas = torch.from_numpy(datas)\n",
        "                datas = self.__map_fn(datas)\n",
        "                yield datas\n",
        "            else:\n",
        "                if (self.shuffle):\n",
        "                    self.permutation = np.random.permutation(self.size)\n",
        "        except Exception as e:\n",
        "            self.__show_exception(e)\n",
        "\n",
        "    def take(self, size):\n",
        "        try:\n",
        "            for i, data in zip(range(size), self()):\n",
        "                yield data\n",
        "            else:\n",
        "                pass\n",
        "        except Exception as e:\n",
        "            self.__show_exception(e)\n",
        "\n",
        "    def __show_exception(self, e) -> None:\n",
        "        tb = traceback.extract_tb(e.__traceback__)\n",
        "        last_call = tb[-1]\n",
        "        print(f\"❌ Error in function '{last_call.name}' at line {last_call.lineno}\")\n",
        "        print(f\"   File: {last_call.filename}\")\n",
        "        print(f\"   Exception: {e}\")\n",
        "\n",
        "    def map(self, fn):\n",
        "        self.maps_fn.append(fn)\n",
        "\n",
        "    def __map_fn(self, data):\n",
        "        for fn in self.maps_fn:\n",
        "            data = fn(*data)\n",
        "        return data"
      ],
      "metadata": {
        "id": "TkXn5Zz1AwF6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(train_ds, batchsize=20, shuffle=False)"
      ],
      "metadata": {
        "id": "d144IRutFDMJ"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader.map(lambda x, y: (normalization_n1_p1(x), one_hot(y, num_classes=10)))"
      ],
      "metadata": {
        "id": "40WpDif0GcuQ"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img, label in dataloader.take(100):\n",
        "    test_dataset_fn(img, label)\n",
        "    #print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7uZwjchzB8SQ",
        "outputId": "711ec734-173b-4fa5-8406-c265edcc27ca"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "img: shape torch.Size([20, 784]), min -1.0, max 1.0, type <class 'torch.Tensor'>;\n",
            "label: shape torch.Size([20, 10]), min 0.0, max 1.0, type <class 'torch.Tensor'>;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizer"
      ],
      "metadata": {
        "id": "G8aGDKmc9tzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "A module to implement the stochastic gradient descent learning\n",
        "algorithm for a feedforward neural network.  Gradients are calculated\n",
        "using backpropagation.\n",
        "\"\"\"\n",
        "\n",
        "class SGD(object):\n",
        "\n",
        "    def __init__(self, parameters, lr):\n",
        "        \"\"\"\n",
        "        parameters - a list of parameters for every layer\n",
        "                    -> list of parameters\n",
        "                        -> one element of parameter is list of torch tensor\n",
        "        lr - learning rate\n",
        "        \"\"\"\n",
        "        self.__parameters = parameters\n",
        "        self.__lr = lr\n",
        "\n",
        "    def __call__(self, grads):\n",
        "        \"\"\"\n",
        "        grads - a list of grads for every layer\n",
        "                    -> list of grads for parameters\n",
        "                        -> one element of grads is list of torch tensor\n",
        "        \"\"\"\n",
        "        #print(\"____optimizer____\")\n",
        "        #print(\"list layers: parameter {}, size {}, grad {}, size {}\".format(type(self.__parameters), len(self.__parameters), type(grads), len(grads)))\n",
        "        for l_parameters, l_grads in zip(self.__parameters, grads):\n",
        "            #print(\"list: parameters {}, grads {}\".format(type(l_parameters), type(l_grads)))\n",
        "            if ((l_grads is not None)):\n",
        "                for parameter, grad in zip(l_parameters, l_grads):\n",
        "                    #print(\"parameter {}, grad {}\".format(parameter.shape, grad.shape))\n",
        "                    #batch_size = grad.size(0)\n",
        "                    #grad = grad.sum(dim=0, keepdim=False)\n",
        "                    #grad = torch.div(grad, batch_size, out=grad)\n",
        "                    #print(\"parameter {}, grad {}\".format(parameter.shape, grad.shape))\n",
        "                    torch.sub(parameter, grad, alpha=self.__lr, out=parameter)\n",
        "\n"
      ],
      "metadata": {
        "id": "jCJPk8PR4YmX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Metrics"
      ],
      "metadata": {
        "id": "UVslqY8VHz_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build MetricsList"
      ],
      "metadata": {
        "id": "AW3g5UadSVzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MetricsList(object):\n",
        "    def __init__(self, metrics_fn):\n",
        "        \"\"\"\"\"\"\n",
        "        if (metrics_fn is not None):\n",
        "            if (isinstance(metrics_fn, (dict))):\n",
        "                for key in metrics_fn.keys():\n",
        "                    if (not isinstance(metrics_fn[key], Metrics)):\n",
        "                        raise NameError(\"The metric: '{}' is type '{}' not as 'Metrics' object\".format(key, type(metrics_fn[key])))\n",
        "            else:\n",
        "                raise NameError(\"The argument need to be as 'Dict' object, but is '{}'\".format(type(metrics_fn)))\n",
        "        else:\n",
        "            pass\n",
        "        #\n",
        "        self.__metrics_fn = metrics_fn\n",
        "\n",
        "    def __call__(self, y, y_pred):\n",
        "        logs = {}\n",
        "        if (self.__metrics_fn is not None):\n",
        "            for key in self.__metrics_fn.keys():\n",
        "                metric = self.__metrics_fn[key](y, y_pred)\n",
        "                logs[key] = metric\n",
        "        return logs\n"
      ],
      "metadata": {
        "id": "Z4RkFcnpH2RN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Metrics"
      ],
      "metadata": {
        "id": "YGAwM2WMSaxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Metrics(object):\n",
        "    def __init__(self, name=\"\"):\n",
        "        \"\"\"\"\"\"\n",
        "        self.name = name\n",
        "\n",
        "    def __call__(self, y_pred, y):\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "UKHTFByoSdJc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Acuracy(Metrics):\n",
        "    def __init__(self, **kw):\n",
        "        super().__init__(**kw)\n",
        "        pass\n",
        "\n",
        "    def __call__(self, y_pred, y):\n",
        "        # y_pred: logits or probabilities (batch_size, num_classes)\n",
        "        # y_true: true labels (batch_size,)\n",
        "        preds = torch.argmax(y_pred, dim=1)\n",
        "        y     = torch.argmax(y,      dim=1)\n",
        "        correct = (preds == y).sum().item()\n",
        "        total = y.size(0)\n",
        "        return correct / total\n"
      ],
      "metadata": {
        "id": "2xIZWnAnU41V"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Callback"
      ],
      "metadata": {
        "id": "o5ucXnc8H2l_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build CallbacksList"
      ],
      "metadata": {
        "id": "pdk7L7ObSgPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CallbacksList(object):\n",
        "    def __init__(self, callbacks):\n",
        "        \"\"\"\"\"\"\n",
        "        if (callbacks is not None):\n",
        "            if (isinstance(callbacks, list)):\n",
        "                    for i, callback in enumerate(callbacks, 0):\n",
        "                        if (not isinstance(callback, (type(Callbacks()), type(PlotLossesKeras())))):\n",
        "                            raise NameError(\"The callback: '{}' is type '{}' not as 'Callbacks' object\".format(i, type(callback)))\n",
        "            else:\n",
        "                raise NameError(\"The argument need to be as 'List' object, but is '{}'\".format(type(callbacks)))\n",
        "        else:\n",
        "            callbacks = []\n",
        "        #\n",
        "        self.__callbacks = callbacks\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_batch_begin(batch, logs)\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_batch_end(batch, logs)\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_epoch_begin(epoch, logs)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_epoch_end(epoch, logs)\n",
        "\n",
        "    def on_predict_batch_begin(self, batch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_predict_batch_begin(batch, logs)\n",
        "\n",
        "    def on_predict_batch_end(self, batch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_predict_batch_end(batch, logs)\n",
        "\n",
        "    def on_predict_begin(self, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_predict_begin(logs)\n",
        "\n",
        "    def on_predict_end(self, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_predict_end(logs)\n",
        "\n",
        "    def on_test_batch_begin(self, batch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_test_batch_begin(batch, logs)\n",
        "\n",
        "    def on_test_batch_end(self, batch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_test_batch_end(batch, logs)\n",
        "\n",
        "    def on_test_begin(self, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_test_begin(logs)\n",
        "\n",
        "    def on_test_end(self, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_test_end(logs)\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_train_batch_begin(batch, logs)\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_train_batch_end(batch, logs)\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_train_begin(logs)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        for callback in self.__callbacks:\n",
        "            callback.on_train_end(logs)\n"
      ],
      "metadata": {
        "id": "iE4K8V6aH8Pk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Callbacks"
      ],
      "metadata": {
        "id": "rC-Fusm36iXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Callbacks(object):\n",
        "    def __init__(self,):\n",
        "        \"\"\"\"\"\"\n",
        "        pass\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_predict_batch_begin(self, batch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_predict_batch_end(self, batch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_predict_begin(self, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_predict_end(self, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_test_batch_begin(self, batch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_test_batch_end(self, batch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_test_begin(self, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_test_end(self, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "t3wLdybR6ltJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Layers"
      ],
      "metadata": {
        "id": "1Wr49EeH1m_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Layer"
      ],
      "metadata": {
        "id": "kCNgANQO5sAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Layer(object):\n",
        "    def __init__(self, name=\"layer\"):\n",
        "        torch.set_grad_enabled(False) # do not use pythorch gradient\n",
        "        self.name = name\n",
        "        self.__parameters = []\n",
        "        self.__grads = None\n",
        "        self.__is_derivable = False\n",
        "\n",
        "    def set_is_derivable(self, bVal):\n",
        "        self.__is_derivable = bVal\n",
        "\n",
        "    def set_grads(self, grads):\n",
        "        self.__grads = grads\n",
        "\n",
        "    def is_derivable(self):\n",
        "        return self.__is_derivable\n",
        "\n",
        "    def get_grads(self):\n",
        "        return self.__grads\n",
        "\n",
        "    def _init_param(self, shape, init_fn):\n",
        "        if (init_fn is not None):\n",
        "            x = init_fn(shape)\n",
        "        else:\n",
        "            # init like glorot uniform\n",
        "            lim = np.sqrt(6/np.sum(shape))\n",
        "            x = torch.empty(*shape).uniform_(-lim, lim)\n",
        "        self.__parameters.append(x)\n",
        "        return x\n",
        "\n",
        "    def backward(self, x):\n",
        "        raise NameError(\"Layer {}: The method 'backward' is not implemented\".format(self.name))\n",
        "\n",
        "    def get_prime(self, features):\n",
        "        return None\n",
        "\n",
        "    def get_weights(self):\n",
        "        return None\n",
        "\n",
        "    def parameters(self):\n",
        "        return self.__parameters\n",
        "\n",
        "    def copy(self):\n",
        "        copy_params = []\n",
        "        for param in self.__parameters:\n",
        "            c_param = torch.empty(param.size(), dtype=torch.float32)\n",
        "            c_param.copy_(param, non_blocking=False)\n",
        "            copy_params.append(c_param)\n",
        "        return copy_params\n",
        "\n",
        "    def cmp(self, parameters: list):\n",
        "        is_equal = True\n",
        "        print(\"layer {}, size: loc {}, par {}\".format(self.name, len(self.__parameters), len(parameters)))\n",
        "        for loc_parameters, c_parameters in zip(self.__parameters, parameters):\n",
        "            is_equal = is_equal and torch.allclose(loc_parameters, c_parameters)\n",
        "        return is_equal\n",
        "\n",
        "    def __call__(self, x):\n",
        "        raise NameError(\"Layer {}: The method '__call__' is not implemented\".format(self.name))\n"
      ],
      "metadata": {
        "id": "Dda0Ro4t5uZe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_l = Layer(name=\"test\")"
      ],
      "metadata": {
        "id": "CNS-o5cc697h"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Input layer"
      ],
      "metadata": {
        "id": "STQxIDrfjGhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class InputLayer(Layer):\n",
        "    def __init__(self, **kw):\n",
        "        super().__init__(**kw)\n",
        "        self.set_is_derivable(False)\n",
        "\n",
        "    def backward(self, delta, features):\n",
        "        self.set_grads(None)\n",
        "\n",
        "    def get_prime(self, features):\n",
        "        return None\n",
        "\n",
        "    def get_weights(self):\n",
        "        return None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "eivNe4zujJtZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Dense layer"
      ],
      "metadata": {
        "id": "kkCJdVkn1vwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Dense(Layer):\n",
        "    def __init__(self, in_size, out_size, init_fn=None, use_bias=False, init_fn_b=None, **kw):\n",
        "        super().__init__(**kw)\n",
        "        self.__use_bias = use_bias\n",
        "        self.__w = self._init_param((in_size, out_size), init_fn)\n",
        "        if (self.__use_bias):\n",
        "            self.__b = self._init_param((out_size, ), init_fn_b)\n",
        "        self.set_is_derivable(False)\n",
        "\n",
        "    def backward(self, delta, features):\n",
        "        # get batch size\n",
        "        batch_size = features.size(0)\n",
        "        # calculate bias gradients\n",
        "        if (self.__use_bias):\n",
        "            nabla_b = delta.sum(dim=0)\n",
        "            torch.div(nabla_b, batch_size, out=nabla_b)\n",
        "            #print(\"----nabla_b\", nabla_b.shape)\n",
        "        # perform dimensions\n",
        "        features = features.transpose(1, 0)\n",
        "        #print(\"----delta\", delta.shape)\n",
        "        #print(\"----features\", features.shape)\n",
        "        # calculate weight gradients\n",
        "        nabla_w = torch.matmul(features, delta)# w = Ft*D\n",
        "        torch.div(nabla_w, batch_size, out=nabla_w)\n",
        "        #print(\"----nabla_w\", nabla_w.shape)\n",
        "        # set gradients\n",
        "        grads = [nabla_w]\n",
        "        if (self.__use_bias):\n",
        "            grads.append(nabla_b)\n",
        "        self.set_grads(grads)\n",
        "\n",
        "    def get_prime(self, features):\n",
        "        return None\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.__w\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = torch.matmul(x, self.__w)\n",
        "        if (self.__use_bias):\n",
        "            x = torch.add(x, self.__b)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "yHV4lyJkPRTw"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    def backward(self, delta, features):\n",
        "        batch_size = features.size(0)\n",
        "        #delta    = delta.unsqueeze(1)\n",
        "        features = features.transpose(1, 0)\n",
        "        #print(\"----delta\", delta.shape)\n",
        "        #print(\"----features\", features.shape)\n",
        "\n",
        "        nabla_w = torch.matmul(features, delta)# w = Ft*D\n",
        "        torch.div(nabla_w, batch_size, out=nabla_w)\n",
        "        #print(\"----nabla_w\", nabla_w.shape)\n",
        "        nabla_b = delta.sum(dim=0)\n",
        "        torch.div(nabla_b, batch_size, out=nabla_b)\n",
        "        #print(\"----nabla_b\", nabla_b.shape)\n",
        "        grads = [nabla_w, nabla_b]\n",
        "        self.set_grads(grads)\n",
        "    \"\"\"\n",
        "    def backward(self, delta, features):\n",
        "        # get batch size\n",
        "        batch_size = features.size(0)\n",
        "        # calculate nabla for bias\n",
        "        if (self.__use_bias):\n",
        "            nabla_b = delta.sum(dim=0)\n",
        "            torch.div(nabla_b, batch_size, out=nabla_b)\n",
        "            #print(\"----nabla_b\", nabla_b.shape)\n",
        "        # prepare dimensions\n",
        "        delta    = delta.unsqueeze(1)\n",
        "        features = features.unsqueeze(-1)\n",
        "        #print(\"----delta\", delta.shape)\n",
        "        #print(\"----features\", features.shape)\n",
        "\n",
        "        nabla_w = torch.bmm(features, delta)\n",
        "        nabla_w = nabla_w.sum(dim=0)\n",
        "        torch.div(nabla_w, batch_size, out=nabla_w)\n",
        "        #print(\"----nabla_w\", nabla_w.shape)\n",
        "        grads = [nabla_w]\n",
        "        if (self.__use_bias):\n",
        "            grads.append(nabla_b)\n",
        "        self.set_grads(grads)\n",
        "    \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "xf6jp434lCfp",
        "outputId": "48735a66-5c4c-4cf2-cdda-459af81eebf7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef backward(self, delta, features):\\n    # get batch size\\n    batch_size = features.size(0)\\n    # calculate nabla for bias\\n    if (self.__use_bias):\\n        nabla_b = delta.sum(dim=0)\\n        torch.div(nabla_b, batch_size, out=nabla_b)\\n        #print(\"----nabla_b\", nabla_b.shape)\\n    # prepare dimensions\\n    delta    = delta.unsqueeze(1)\\n    features = features.unsqueeze(-1)\\n    #print(\"----delta\", delta.shape)\\n    #print(\"----features\", features.shape)\\n    \\n    nabla_w = torch.bmm(features, delta)\\n    nabla_w = nabla_w.sum(dim=0)\\n    torch.div(nabla_w, batch_size, out=nabla_w)\\n    #print(\"----nabla_w\", nabla_w.shape)\\n    grads = [nabla_w]\\n    if (self.__use_bias):\\n        grads.append(nabla_b)\\n    self.set_grads(grads)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_x = torch.empty(3, 20).uniform_(-1, 1)  # Uniform [-1, 1]\n",
        "tmp_x = torch.ones(2, 3, 20)  # Uniform [-1, 1]\n",
        "print(tmp_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-G7YogWSi5r",
        "outputId": "2fc6f5a9-85e2-4f6d-965b-de1b71545871"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense_l = Dense(in_size=20, out_size=3, use_bias=True)"
      ],
      "metadata": {
        "id": "wOhpSQ1laMJ-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense_l(tmp_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-O0adhIa5PO",
        "outputId": "60ac5c98-b8f0-41f9-e71d-c4fb1296f7de"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.1257, -1.0865, -1.1252],\n",
              "         [ 1.1257, -1.0865, -1.1252],\n",
              "         [ 1.1257, -1.0865, -1.1252]],\n",
              "\n",
              "        [[ 1.1257, -1.0865, -1.1252],\n",
              "         [ 1.1257, -1.0865, -1.1252],\n",
              "         [ 1.1257, -1.0865, -1.1252]]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense_l.backward(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "5vSJG4MJfhWS",
        "outputId": "f228bff3-508f-4d23-f4c0-f34ae9391e09"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Dense.backward() missing 1 required positional argument: 'features'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-312491865.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdense_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: Dense.backward() missing 1 required positional argument: 'features'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Relu layer"
      ],
      "metadata": {
        "id": "hUCepVut2W9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Relu(Layer):\n",
        "    def __init__(self, min=0, **kw):\n",
        "        super().__init__(**kw)\n",
        "        self.__min = torch.tensor(min)\n",
        "        self.set_is_derivable(True)\n",
        "\n",
        "    def backward(self, delta, features):\n",
        "        self.set_grads(None)\n",
        "\n",
        "    def get_prime(self, features):\n",
        "        return (features > 0).float()\n",
        "\n",
        "    def get_weights(self):\n",
        "        return None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = torch.maximum(x, self.__min)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "IlG2IsMs2aoS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_x = torch.empty(3, 20).uniform_(-1, 1)  # Uniform [-1, 1]\n",
        "#tmp_x = torch.ones(2, 3, 20)  # Uniform [-1, 1]\n",
        "print(tmp_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQAhto3u4GHd",
        "outputId": "e0eb7d2a-3646-407b-b820-9fe6f4a40dd9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2147,  0.7854,  0.6982,  0.7165,  0.9628, -0.0168, -0.7561, -0.0126,\n",
            "         -0.0143,  0.2169,  0.4241, -0.5057, -0.4185,  0.0529,  0.4176,  0.7627,\n",
            "          0.2612, -0.9293, -0.8287,  0.1271],\n",
            "        [ 0.0707,  0.9269, -0.8177,  0.3035, -0.4018,  0.1338, -0.4901, -0.1726,\n",
            "          0.5371, -0.8540, -0.5457,  0.8025, -0.3467, -0.2213, -0.4189, -0.5081,\n",
            "          0.8426,  0.9289,  0.8051,  0.2765],\n",
            "        [ 0.4647,  0.5800, -0.9863, -0.9222, -0.1540, -0.9986,  0.4406,  0.7460,\n",
            "          0.9229, -0.0899,  0.8097,  0.3678, -0.8543, -0.0504,  0.9877,  0.0411,\n",
            "          0.2094, -0.5094,  0.6172, -0.0490]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relu_l = Relu(min=0)"
      ],
      "metadata": {
        "id": "sEVNXQ-M4qqG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relu_l(tmp_x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Fxqjc074wYh",
        "outputId": "4993a18c-5a38-46e9-d679-6b57bab57836"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relu_l.get_prime().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "6c66vNb34_1D",
        "outputId": "abe241c0-5ede-46de-bf39-90e9d82eec15"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Relu.get_prime() missing 1 required positional argument: 'features'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3436263032.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrelu_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: Relu.get_prime() missing 1 required positional argument: 'features'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build softmax layer"
      ],
      "metadata": {
        "id": "-OVh9YZo02Fl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Softmax(Layer):\n",
        "    def __init__(self, **kw):\n",
        "        super().__init__(**kw)\n",
        "        self.set_is_derivable(True)\n",
        "\n",
        "    def backward(self, delta, features):\n",
        "        self.set_grads(None)\n",
        "    \"\"\"\n",
        "    def get_prime(self, features):\n",
        "        # Suppose softmax over channel dim\n",
        "        x = self(features)\n",
        "        x_flat = x.reshape(-1, x.shape[-1])  # collapse batch*H*W into one dimension\n",
        "        # batch matrix multiplication\n",
        "        x_bmm = torch.bmm(x_flat.unsqueeze(2), x_flat.unsqueeze(1))\n",
        "        jacobian = torch.diag_embed(x_flat) - x_bmm\n",
        "        jacobian = jacobian.sum(dim=-1, keepdim=False)\n",
        "        return jacobian\n",
        "    \"\"\"\n",
        "\n",
        "    def get_prime(self, features):\n",
        "        # Suppose softmax over channel dim\n",
        "        x = self(features)\n",
        "        diff = torch.sub(1, x, alpha=1, out=None)\n",
        "        x = torch.mul(x, diff, out=x)\n",
        "        return x\n",
        "\n",
        "    def get_weights(self):\n",
        "        return None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = torch.exp(x) - torch.max(x)\n",
        "        x = torch.div(x, torch.sum(x), rounding_mode=None, out=None)\n",
        "        return x\n",
        "\n",
        "def softmax(x, derivative = False):\n",
        "    # for stability, we shift values down so max = 0\n",
        "    # https://cs231n.github.io/linear-classify/#softmax\n",
        "    exp_shifted = np.exp(x - x.max())\n",
        "    if derivative:\n",
        "        return exp_shifted / np.sum(exp_shifted, axis = 0) * (1 - exp_shifted / np.sum(exp_shifted, axis = 0))\n",
        "    else:\n",
        "        return exp_shifted / np.sum(exp_shifted, axis = 0)"
      ],
      "metadata": {
        "id": "5fQJ6gc607ig"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_x = torch.empty(3, 20).uniform_(-1, 1)  # Uniform [-1, 1]\n",
        "#tmp_x = torch.ones(2, 3, 20)  # Uniform [-1, 1]\n",
        "print(tmp_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99z6B2iC4bAD",
        "outputId": "07a9fbe2-ce17-48a2-ddf0-fbafc2409c28"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2362,  0.4914, -0.5989,  0.5817, -0.1990, -0.4743, -0.4052, -0.5721,\n",
            "          0.0346, -0.3257,  0.3997,  0.9869, -0.1369,  0.8468,  0.2440,  0.3187,\n",
            "         -0.3427, -0.2786, -0.9753, -0.3535],\n",
            "        [-0.1218,  0.8696,  0.6346,  0.7159, -0.5462, -0.9119,  0.3980, -0.8161,\n",
            "          0.9467,  0.3217,  0.0708,  0.0147, -0.8290,  0.4878,  0.3823, -0.3581,\n",
            "          0.4144,  0.1264,  0.9421,  0.5322],\n",
            "        [ 0.3252, -0.3648, -0.1405,  0.1632,  0.5896,  0.5241,  0.5790,  0.4439,\n",
            "          0.2877, -0.9869, -0.6017, -0.8320, -0.1324,  0.5844,  0.8483, -0.0297,\n",
            "         -0.5137, -0.4017, -0.3747, -0.6301]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_l = Softmax()"
      ],
      "metadata": {
        "id": "O1UPSCAa4dOX"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_l(tmp_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMg6M0e_4hNI",
        "outputId": "66582ad2-0bb1-4147-f2e6-0e6e11463ffb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0111, 0.0230, 0.0077, 0.0251, 0.0115, 0.0087, 0.0094, 0.0079, 0.0145,\n",
              "         0.0101, 0.0210, 0.0377, 0.0123, 0.0328, 0.0179, 0.0193, 0.0100, 0.0106,\n",
              "         0.0053, 0.0099],\n",
              "        [0.0124, 0.0335, 0.0265, 0.0287, 0.0081, 0.0056, 0.0209, 0.0062, 0.0362,\n",
              "         0.0194, 0.0151, 0.0143, 0.0061, 0.0229, 0.0206, 0.0098, 0.0213, 0.0159,\n",
              "         0.0360, 0.0239],\n",
              "        [0.0194, 0.0098, 0.0122, 0.0165, 0.0253, 0.0237, 0.0251, 0.0219, 0.0187,\n",
              "         0.0052, 0.0077, 0.0061, 0.0123, 0.0252, 0.0328, 0.0136, 0.0084, 0.0094,\n",
              "         0.0097, 0.0075]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_l.get_prime().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyWu3Uqu4ohv",
        "outputId": "76b1c6b8-5868-4008-b6f4-b468117dae2a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 20, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build sigmoid layer"
      ],
      "metadata": {
        "id": "CifUve92TEZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Sigmoid(Layer):\n",
        "    def __init__(self, **kw):\n",
        "        super().__init__(**kw)\n",
        "        self.__t = torch.tensor(1.)\n",
        "        self.set_is_derivable(True)\n",
        "\n",
        "    def backward(self, delta, features):\n",
        "        self.set_grads(None)\n",
        "\n",
        "    def get_prime(self, features):\n",
        "        # Suppose softmax over channel dim\n",
        "        x = self(features)\n",
        "        diff = torch.sub(self.__t, x, alpha=1, out=None)\n",
        "        x = torch.mul(x, diff, out=x)\n",
        "        return x\n",
        "\n",
        "    def get_weights(self):\n",
        "        return None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = torch.exp(-x, out=x)\n",
        "        x = torch.add(x, self.__t, alpha=1, out=x)\n",
        "        x = torch.div(self.__t, x, out=x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "IUmoei9uTE1A"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Model"
      ],
      "metadata": {
        "id": "2QT0wNGq1udy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "A module to implement the stochastic gradient descent learning\n",
        "algorithm for a feedforward neural network.  Gradients are calculated\n",
        "using backpropagation.  Note that I have focused on making the code\n",
        "simple, easily readable, and easily modifiable.  It is not optimized,\n",
        "and omits many desirable features.\n",
        "\"\"\"\n",
        "\n",
        "class Model(object):\n",
        "    def __init__(self, device):\n",
        "        \"\"\"\"\"\"\n",
        "        self.__device = device\n",
        "        self.__layers = []\n",
        "        self.__parameteres  = []\n",
        "        self.__out_features = []\n",
        "        self.__metrics_fn = None\n",
        "\n",
        "    def serialization(self, layers: list):\n",
        "        if (isinstance(layers, list)):\n",
        "            for i, layer in enumerate(layers, 0):\n",
        "                if (not isinstance(layer, Layer)):\n",
        "                    raise NameError(\"The layer: '{}' is not as 'Layer' object\".format(i))\n",
        "            self.__layers = layers\n",
        "        else:\n",
        "            raise NameError(\"The argument need to be as 'List' object, but is '{}'\".format(type(layers)))\n",
        "\n",
        "    def compile(self, optimizer, loss, metrics, callbacks):\n",
        "        self.optimizer = optimizer\n",
        "        self.loss_fn = loss\n",
        "        self.metric_fn = MetricsList(metrics)\n",
        "        self.callbacks = CallbacksList(callbacks)\n",
        "\n",
        "    def backward(self, loss):\n",
        "        layer = self.__layers[-1]\n",
        "        delta = loss\n",
        "        #print(\"layer {}, shape 'delta' {}\".format(layer.name, delta.shape))\n",
        "        if (layer.is_derivable()):\n",
        "            prime_fn = self.__layers[-1].get_prime\n",
        "            #print(\"layer {}, '{}'\".format(layer.name, \"derivable\"))\n",
        "        else:\n",
        "            prime_fn = None\n",
        "            # output of the second-last layer\n",
        "            prev_features = self.__out_features[-2]\n",
        "            features = self.__out_features[-1]\n",
        "            # calculate the gradient for the cost function C_x\n",
        "            delta = torch.empty(features.size(), dtype=torch.float32)\n",
        "            delta = torch.add(delta, loss, alpha=1, out=delta)\n",
        "            layer.backward(delta, prev_features)\n",
        "            #print(\"layer {}, prev_layer '{}', D*Ft\".format(layer.name, self.__layers[-2].name))\n",
        "\n",
        "        #print(\"+++++++++++++++++++++++++++++++++++++++++\")\n",
        "        # backprop\n",
        "        for l in range(2, len(self.__layers), 1):\n",
        "            layer = self.__layers[-l]\n",
        "            print(\"layer {}, shape: 'delta' {}\".format(layer.name, delta.shape))\n",
        "            # -----------\n",
        "            weights = self.__layers[-l+1].get_weights()\n",
        "            if (weights is not None):\n",
        "                print(\"\\tnext_layer {}, shape: 'weights' {}, 'delta' {}, D*Wt\".format(self.__layers[-l+1].name, weights.shape, delta.shape))\n",
        "                weights = weights.transpose(1, 0)\n",
        "                delta   = torch.matmul(weights, delta)\n",
        "                print(\"'weights' -l+1, shape {}\".format(weights.shape))\n",
        "                print(\" 'delta' -l, shape {}\".format(delta.shape))\n",
        "            else:\n",
        "                #print(\"not 'weights' -l+1\")\n",
        "                #print(\" 'delta' -l, shape {}\".format(delta.shape))\n",
        "                #print(\"\\tnext_layer {} not 'weights', \".format(self.__layers[-l+1].name))\n",
        "                pass\n",
        "\n",
        "            # =========\n",
        "            if (prime_fn is not None):\n",
        "                # Derivative of the last layer\n",
        "                # calculate gradients for layer -l\n",
        "                features = self.__out_features[-l]\n",
        "                prime = prime_fn(features)\n",
        "                #print(\"\\tnext_layer {}, shape: 'prime' {}, 'delta' {}, D*P\".format(self.__layers[-l+1].name, prime.shape, delta.shape))\n",
        "                delta = torch.mul(delta, prime)\n",
        "                #print(\"'prime' -l+1, shape {}\".format(prime.shape))\n",
        "                #print(\" 'delta' -l, shape {}\".format(delta.shape))\n",
        "            else:\n",
        "                #print(\"not 'prime' -l+1\")\n",
        "                #print(\" 'delta' -l, shape {}\".format(delta.shape))\n",
        "                #print(\"\\tnext_layer {} not 'prime', \".format(self.__layers[-l+1].name))\n",
        "                pass\n",
        "\n",
        "            if (layer.is_derivable()):\n",
        "                prime_fn = layer.get_prime\n",
        "                #print(\"'derivable' -l {}\".format(l))\n",
        "                #print(\"layer {} 'derivable'\".format(layer.name))\n",
        "            else:\n",
        "                prime_fn = None\n",
        "                # calculate gradients for layer -l\n",
        "                features = self.__out_features[-l-1]\n",
        "                #print(\"'not derivable' -l, shape {}\".format(features.shape))\n",
        "                #print(\" 'delta' -l, shape {}\".format(delta.shape))\n",
        "                layer.backward(delta, features)\n",
        "                #print(\"layer {}, prev_layer {}, not 'derivable', D*Ft\".format(layer.name, self.__layers[-l-1].name))\n",
        "        #print(\"+++++++++++++++++++++++++++++++++++++++++\")\n",
        "\n",
        "    def get_grads(self):\n",
        "        grads = []\n",
        "        for layer in self.__layers:\n",
        "            grads.append(layer.get_grads())\n",
        "        return grads\n",
        "\n",
        "    def parameters(self):\n",
        "        parameteres = []\n",
        "        for layer in self.__layers:\n",
        "            parameteres.append(layer.parameters())\n",
        "        return parameteres\n",
        "\n",
        "    def forward(self, train_ds, test_ds=None, epochs=1):\n",
        "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
        "        if (not isinstance(train_ds, DataLoader)):\n",
        "            raise NameError(\"The train dataset: is type '{}' not as 'DataLoader' object\".format(type(train_ds)))\n",
        "        # start training\n",
        "        self.callbacks.on_train_begin()\n",
        "        for epoch in range(epochs):\n",
        "            epoch_logs = self.train_batch(epoch, train_ds)\n",
        "        self.callbacks.on_train_end(epoch_logs)\n",
        "        return None\n",
        "\n",
        "    def train_batch(self, epoch, train_ds):\n",
        "        self.callbacks.on_epoch_begin(epoch)\n",
        "        batch_logs = {}\n",
        "        for i, data in zip(range(len(train_ds)), train_ds()):\n",
        "        #for i, data in zip(range(1), train_ds()):\n",
        "            self.callbacks.on_train_batch_begin(i)\n",
        "            batch_logs = self.train_step(data)\n",
        "            self.callbacks.on_train_batch_end(i, batch_logs)\n",
        "            # Empty cached memory\n",
        "            torch.cuda.empty_cache()\n",
        "        self.callbacks.on_epoch_end(epoch, batch_logs)\n",
        "\n",
        "    def train_step(self, data):\n",
        "        img, y = data\n",
        "        #print(\"type img {}\".format(type(img)))\n",
        "        img = img.to(self.__device)\n",
        "        y   = y.to(self.__device)\n",
        "        y_pred = self(img)\n",
        "        #print(\"y_pred {}, y {}\".format(y_pred.shape, y.shape))\n",
        "        loss = self.loss_fn(y_pred, y)\n",
        "        #print(\"loss {}, data @{}@\".format(loss.shape, loss))\n",
        "        metrics = self.metric_fn(y_pred, y)\n",
        "        self.backward(loss)\n",
        "        grads = self.get_grads()\n",
        "        self.optimizer(grads)\n",
        "        loss = torch.mean(loss)\n",
        "        logs = {\"loss\":loss}\n",
        "        logs.update(metrics)\n",
        "        return logs\n",
        "\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        y = inputs\n",
        "        #print(\"model: shape {}\".format(y.shape))\n",
        "        for layer in self.__layers:\n",
        "            y = layer(y)\n",
        "            #print(\"model: name {}, shape {}\".format(layer.name, y.shape))\n",
        "            self.__out_features.append(y)\n",
        "        return y\n",
        "\n",
        "    def copy(self):\n",
        "        parameteres = []\n",
        "        for layer in self.__layers:\n",
        "            parameteres.append(layer.copy())\n",
        "        return parameteres\n",
        "\n",
        "    def cmp(self, m_parameters):\n",
        "        is_equal = True\n",
        "        for layer, l_parameters in zip(self.__layers, m_parameters):\n",
        "            tmp_equal = layer.cmp(l_parameters)\n",
        "            print(\"layer {}, cmp {}\".format(layer.name, tmp_equal))\n",
        "            is_equal = is_equal and tmp_equal\n",
        "        return is_equal\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "        \"\"\"Return the number of test inputs for which the neural\n",
        "        network outputs the correct result. Note that the neural\n",
        "        network's output is assumed to be the index of whichever\n",
        "        neuron in the final layer has the highest activation.\"\"\"\n",
        "        test_results = [(np.argmax(self.feedforward(x)), y)\n",
        "                        for (x, y) in test_data]\n",
        "        return sum(int(x == y) for (x, y) in test_results)\n",
        "\n",
        "    def cost_derivative(self, output_activations, y):\n",
        "        \"\"\"Return the vector of partial derivatives partial C_x\n",
        "        partial a for the output activations.\"\"\"\n",
        "        return (output_activations-y)\n"
      ],
      "metadata": {
        "id": "JH_jOksz4Yd8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_x = torch.ones(2, 3, 20)  # Uniform [-1, 1]\n",
        "print(tmp_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHI_6IyE4Yay",
        "outputId": "43517622-652c-48a2-e799-014a03f271e7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "          1., 1., 1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_x.transpose(2, 1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2JcAsVA4YXS",
        "outputId": "e25cf740-dd2f-4f39-ecca-b7ee90e2ae7c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 20, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "gXc4vD9GdCvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipiline\n",
        "train_ds = ExtendedMNISTDataset(root=\"/content\", train=True)\n",
        "test_ds = ExtendedMNISTDataset(root=\"/content\", train=False)\n",
        "# Data loader\n",
        "train_loader = DataLoader(train_ds, batchsize=32, shuffle=True)\n",
        "train_loader.map(lambda x, y: (normalization_n1_p1(x), one_hot(y, num_classes=10)))\n",
        "test_loader  = DataLoader(test_ds,  batchsize=20, shuffle=False)\n",
        "test_loader.map(lambda x, y: (normalization_n1_p1(x), one_hot(y, num_classes=10)))"
      ],
      "metadata": {
        "id": "J3XwtU2uc8so"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if torch.accelerator.is_available():\n",
        "    device=torch.accelerator.current_accelerator()\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qq0Ft24dTZ9",
        "outputId": "d57205a6-4bf0-4298-b7e9-771f0c615fbd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "6V07jRYzombR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pyTorch_init(shape):\n",
        "    lim = np.sqrt(1./shape[0])\n",
        "    return torch.empty(*shape).uniform_(-lim, lim)"
      ],
      "metadata": {
        "id": "BjvLDYmfCmKK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyTorch_init((784, 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxgOFnw6C-8Z",
        "outputId": "fcc58f8f-dfe0-44c7-b1de-b2c6f77057ba"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0212, -0.0007,  0.0307,  ..., -0.0253,  0.0320, -0.0086],\n",
              "        [-0.0221,  0.0266,  0.0270,  ..., -0.0140, -0.0177, -0.0270],\n",
              "        [ 0.0352, -0.0165,  0.0026,  ...,  0.0136,  0.0030,  0.0243],\n",
              "        ...,\n",
              "        [-0.0241,  0.0234,  0.0172,  ..., -0.0206, -0.0097, -0.0311],\n",
              "        [-0.0201, -0.0265, -0.0096,  ..., -0.0115, -0.0129, -0.0171],\n",
              "        [-0.0033,  0.0141, -0.0233,  ..., -0.0222,  0.0183, -0.0057]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Model(device=device)\n",
        "layers = [\n",
        "    InputLayer(name=\"Inputs\"),\n",
        "    Dense(784, 100, init_fn=pyTorch_init, use_bias=True, init_fn_b=pyTorch_init, name=\"Dense_h1\"),\n",
        "    #Relu(name=\"Relu_h0\"),\n",
        "    Dense(100, 10, init_fn=pyTorch_init, use_bias=True, init_fn_b=pyTorch_init, name=\"Dense_h2\"),\n",
        "    #Relu(name=\"Relu_h1\"),\n",
        "    #Dense(200, 100, init_fn=None, use_bias=False, init_fn_b=None, name=\"Dense_h2\"),\n",
        "    #Relu(name=\"Relu_h2\"),\n",
        "    #Dense(100, 10, init_fn=None, use_bias=False, init_fn_b=None, name=\"Dense_h3\"),\n",
        "    Softmax(name=\"Softmax_out\"),\n",
        "    #Sigmoid(name=\"sigmoid\"),\n",
        "]\n",
        "model.serialization(layers)"
      ],
      "metadata": {
        "id": "2Rl5P8u8ex62"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_model = model.copy()"
      ],
      "metadata": {
        "id": "eGJDuTWu59nk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.cmp(c_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHxve_ij69D9",
        "outputId": "86a9ad5a-3777-4f54-a917-8f499bed5f11"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer Inputs, size: loc 0, par 0\n",
            "layer Inputs, cmp True\n",
            "layer Dense_h1, size: loc 2, par 2\n",
            "layer Dense_h1, cmp True\n",
            "layer Dense_h2, size: loc 2, par 2\n",
            "layer Dense_h2, cmp True\n",
            "layer Softmax_out, size: loc 0, par 0\n",
            "layer Softmax_out, cmp True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_derivative(output_activations, y):\n",
        "    \"\"\"Return the vector of partial derivatives partial C_x\n",
        "    partial a for the output activations.\"\"\"\n",
        "    return (output_activations-y)**2"
      ],
      "metadata": {
        "id": "Vadvn2V7Gto2"
      },
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cros_entropy = torch.nn.CrossEntropyLoss()\n",
        "#cros_entropy = F.cross_entropy\n",
        "optimizer = SGD(model.parameters(), lr=0.0001)\n",
        "plot_losses = PlotLossesKeras()\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=cros_entropy,\n",
        "    metrics={\"acuracy\":Acuracy(name=\"acuracy\")},\n",
        "    callbacks=[plot_losses\n",
        "               ],\n",
        "    )"
      ],
      "metadata": {
        "id": "3gNj4zczfbHl"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.forward(train_loader, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "-Ul0nrBehP2Y",
        "outputId": "8d48fd77-7a44-49ca-8188-fe2a5ac82c61"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer Dense_h2, shape: 'delta' torch.Size([])\n",
            "layer Dense_h1, shape: 'delta' torch.Size([32, 10])\n",
            "\tnext_layer Dense_h2, shape: 'weights' torch.Size([100, 10]), 'delta' torch.Size([32, 10]), D*Wt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (10x100 and 32x10)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2210941560.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3485048502.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, train_ds, test_ds, epochs)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3485048502.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, epoch, train_ds)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m#for i, data in zip(range(1), train_ds()):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m# Empty cached memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3485048502.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m#print(\"loss {}, data @{}@\".format(loss.shape, loss))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3485048502.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\tnext_layer {}, shape: 'weights' {}, 'delta' {}, D*Wt\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mdelta\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'weights' -l+1, shape {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" 'delta' -l, shape {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10x100 and 32x10)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.cmp(c_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJupY-AF91To",
        "outputId": "b75528f5-2823-4c91-c24c-8ca2a2b30bd0"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer Inputs, size: loc 0, par 0\n",
            "layer Inputs, cmp True\n",
            "layer Dense_h1, size: loc 1, par 1\n",
            "layer Dense_h1, cmp False\n",
            "layer Dense_h2, size: loc 1, par 1\n",
            "layer Dense_h2, cmp False\n",
            "layer Softmax_out, size: loc 0, par 0\n",
            "layer Softmax_out, cmp True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_grads()[3][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "jd7ReYbLaYIe",
        "outputId": "3a131002-663d-4c81-858d-557e1a25c9dc"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2528488726.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    }
  ]
}